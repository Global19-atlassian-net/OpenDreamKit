\ednote{TW@MK: Is this the right place for a Jupyter intro; or should this be moved to the introduction?}
Jupyter works similar in a REPL-like fashion, we give a brief introduction here for a more detailed description we refer the interested reader to \ednote{Citation}. 
Notebooks consist of a set of so-called cells. 
Each cell either contains either rich text, or code that can be evaluated. 
The Jupyter user interface is implemented using TypeScript in the browser, the backend is implemented in Python and delegates the programming-language specific features to so-called kernels via a networking protocol. 
Each kernel works exactly like a REPL, that is they receive the user input in the code cells and produce output that should be presented to the user. 
Additionally, kernels can implement custom interactions using widgets, custom user interface components that communicate directly with the kernel.  
Kernels for a specific programming language are typically implemented in that programming language, to ease implementation and make use of existing tool support. 

We designed and implemented a Jupyter kernel for MMT.
We describe its interface in Section~\ref{sec:kernel:syntax}, the implementation in Section~\ref{sec:kernel:impl} and our conversion between MMT datastructures and notebook in Section~\ref{sec:kernel:mapping}.
In Section~\ref{sec:kernel:widgets}, we describe and discuss our implementation of widgets within our kernel. 

\subsection{Interface}\label{sec:kernel:syntax}

MMT differs from typical computational engines in Jupyter in that it does not only (and not even primarily) perform computation but also handles symbolic expressions with uninterpreted function symbols, whose semantics is described by logical axioms.
Another important difference is how MMT handles context and background knowledge.
Kernels for (mathematics-oriented or general purpose) programming languages, as typical in Jupyter, build and maintain a dynamic context of declarations with imperative assignment and stack-oriented shadowing and rely on a fixed --- often object-oriented --- background library of computational functionality.
MMT, on the other hand, uses graphs of inter-connected theories to represent a multitude of possible contexts and background libraries and to move knowledge between contexts.
To adequately handle these subtleties, we systematically specified a new interface for Jupyter-style interactions with MMT.

\paragraph{Sessions}
On top of the notebook abstraction, Jupyter interactions are managed in \textbf{sessions}: every browser page opening a notebook creates a new session.

MMT already has an abstraction that can closely model a notebook, called a document \ednote{TW@FR/MK: Is there anything that can be referenced here?}. 
In MMT terms, a document is a narrative construct that contains a set of declarations. 
Each input within the Jupyter session can be represented as a single declaration within the document; see Section~\ref{sec:kernel:mapping} for further applications of this mapping. 

Thus it makes sense to represent each session as an ephemeral\footnote{We call an MMT document \textbf{ephemeral}, iff it is (at least initially; it can be serialized and saved) created only in memory in the MMT process; apart from this, it behaves like any other MMT document}) MMT document. 
This gives each session a unique MMT URI, which in turn allows full referencing of all document components.
All commands executed within a session manipulate the associated document, most importantly by interactively creating new theories and then calling MMT algorithms on them.
The latter include but are not limited to computation.

\paragraph{Input}
The possible inputs accepted by the MMT kernel are divided into three groups.
\begin{itemize}
\item \textbf{Global management commands} allow displaying and deleting all current sessions.
 In practice, these commands are typically not available to common users, which should only have access to their own session.
\item \textbf{Local management commands} allow starting, quitting, and restarting the current session. These are the main commands issued by the frontend in response to user action.
\item \textbf{Content commands} are the mathematically meaningful commands and described below.
\end{itemize}

The content commands are again divided into three groups:
\begin{itemize}
 \item \textbf{Write-commands} send new content to the MMT backend to build the current MMT document step by step.
   The backend maintains one implicit, ephemeral MMT document for each session, and any write command changes that document.
 \item \textbf{Read-commands} retrieve information from the backend without changing the session's document.
   These include lookups (both in the session document and in any other accessible document) or computations.
  \item \textbf{Interactive-commands} that create a new user interface component allowing the user to interactively read and write MMT content. 
   In the Jupyter system these are implemented as so-called widgets, and technically break the REPL-paradigm. 
   We will not discuss these now; instead we will discuss them in more detail below in Section~\ref{sec:kernel:widgets}. 
\end{itemize}

A write-command typically consists of a single MMT declaration roughly corresponding to a line in a typical MMT source file.
However, the nesting of declarations is very important in MMT.
This is in contrast to many programming language kernels where nesting is often optional, e.g., to define new functions or classes;
for many current kernels, it makes sense to simplify the implementation by requiring that the entire top-level command, including any nesting, be contained in a single cell.

In our MMT kernel, all declarations that may contain nested declarations (most importantly all MMT documents and theories) are split into parts as follows: the header, the list of nested declarations, and a special end-of-nesting marker.
Each of these is communicated in a separate write-command.
The semantics of MMT is carefully designed in such a way that \emph{i}) any local scope arising from nesting has a unique URI, and \emph{ii}) if a well-formed MMT document is built incrementally by appending individual declarations to a currently open local scope, any intermediate document is also well-formed.
This is critical to make our implementation feasible: the MMT kernel maintains the current document as well as the URI of the current scope; any write-command affects the current scope, possibly closing it or creating new subscopes.
This ensures that all nested declarations are parsed and interpreted in the right scope.

For example, the sequence of commands on the left of Figure~\ref{fig:test_theory} builds two nested theories, where the inner one refers to the type \texttt{a} declared in the outer one.
The right-hand side of Figure~\ref{fig:test_theory} shows the equivalent MMT surface syntax on the right.
Semantically, there is no difference between entering the left-hand side interactively via our new kernel or processing the write commands on the right with the standard MMT parser.
\begin{figure}[ht]\centering
\begin{minipage}[c]{9cm}\includegraphics[width=9cm]{../D4.11/test_theory_jupyter}\end{minipage}
\begin{minipage}[c]{3cm}\includegraphics[width=3cm]{../D4.11/test_theory}\end{minipage}
\caption{Content Commands for Building Theory Graphs}\label{fig:test_theory}
\end{figure}
\ednote{TW: Update jupyter screenshot with outputs}

An additional special write-command is \texttt{eval T}.
It interprets \texttt{T} in the current scope, infers its type \texttt{A}, computes its value \texttt{V}, and then adds the declaration \texttt{resI:A=V} to the current theory, where \texttt{I} is a running counter of unnamed declarations.
This corresponds most closely to the REPL functionality in typical Jupyter kernels.

While write-commands correspond closely to the available types of MMT declarations, the set of read-commands is extensible.
For example, the commands \texttt{get U} where \texttt{U} is any MMT URI returns the MMT declaration of that URI.

\paragraph{Output}
The kernel returns the following kinds of return messages:
\begin{itemize}
\item \textbf{Admin messages} are strings returned in response to session management commands.
\item \textbf{New-element messages} return the declaration that was added by a write-command.
\item \textbf{Existing-element messages} return the declaration that was retrieved by a \texttt{get} command.
\end{itemize}
\ednote{TW: This should be implemeneted in this form in the source code; this currently isn't the case but will be a cleanup post-paper-dealine. }
Like read-commands, the set of output messages is extensible.

The new-element and existing-element messages initially return the declaration in MMT's abstract syntax.
And a post-processing layer specific to Jupyter renders them in HTML+presentation MathML.
That way, the core kernel functionality can be reused easily in other frontends than Jupyter.

\subsection{Implementation}\label{sec:kernel:impl}

\paragraph{Overview}

Generally, Jupyter emphasizes protocols that specify the communication between frontend and backend. 
Recall that the frontend is a Jupyter notebook and the backend consists of kernels specific to and implemented in various programming languages.
This requires a certain duplication of implementation and, critically, maintenance, e.g., when implementing xeus, xwidgets and similar libraries for C++.

Because the jupyter backend is mainly implemented in Python, the Python infrastructure for kernels is by far the best developed one, especially when it comes to Jupyter widgets. 
Therefore, it only makes sense to implement our kernel on top of Python.

At the same time actually executing the user's commands requires a strong integration with the MMT implementation, which uses Scala.
That made it advisable to implement all Jupyter-specific functionality, especially the communication and management, in Python, while all mathematically relevant logic is handled in Scala.

Therefore, our implementation consists of three layers.
The top layer (depicted on the left of Figure~\ref{fig:architecture-diagram}) is a Python module that implements the abstract class for Jupyter kernels.
The bottom layer is a Scala class adding a general-purpose REPL to MMT that handles all the logic of MMT documents.
This can be reused easily in other frontends.
User commands are entered on the client and sent to the top layer, which forwards all requests to the bottom layer and all responses from the bottom layer to the client.
The communication between top and bottom layer is handled by a middle layer.
Its main purpose is to bridge between Python and MMT, format results in HTML, and add interactive functionality via widgets.

This bridging of programming languages is a generally difficult problem. 
However in our situation we chose to make use of the Py4J library~\cite{Py4J:on}.
This is a Python-JVM bridge that allows seamless interaction between Python and any JVM-based language (such as Scala).
Thus, our Python kernel can call MMT code directly.
Valuable Py4j features include callbacks from MMT to Python, shared memory (by treating pointers to JVM objects as Python values), and synchronized garbage collection.
That allows our kernel to direclty and easily benefit from future improvements to the MMT backend, without needing to duplicate these improvements in kernel-specific code. 

Py4J is only JVM-specific, not Scala-specific.
That means that some Scala-specific constructs are not readily exposed to Python.
For example, both Python and Scala allow magic methods for treating any object as a function, but the JVM does not; moreover, the magic method is called \texttt{\_\_call\_\_} in Python and \texttt{apply} in Scala.
Similarly, Scala collections like lists are not automatically seen as their counterparts in Python.
Therefore, we wrote a Python module which performs the bureaucracy of matching up advanced Python and Scala features.
This is distribued along with the Jupyter Kernel. 

\subsection{Converting between Jupyter Notebooks and MMT Documents}\label{sec:kernel:mapping}

Recall that we were to closely model each notebook as an MMT document. 
To integrate Jupyter notebooks and MMT documents, we make use of two fortunate design properties:

Firstly, the storage format for Jupyter notebooks is well-documented \ednote{TW: cite \url{https://nbformat.readthedocs.io/en/latest/}}. 
This allowed us to implement an API for Jupyter notebooks that allows us to extract the MMT content of a notebook or to generate a notebook prefilled with some MMT content.

Secondly, MMT abstracts from the file formats used to define content --- it maintains a cross-format knowledge space that accepts content in any format that can be converted into OMDoc.
Special cases include files written in MMT's native surface syntax, sTeX, or any of the existing importers for proof assistant libraries.
We used the above converter Notebook-OMDoc converter to inject Jupyter Notebooks into this shared knowledge space.

Critically, all formats in this cross-format knowledge space can interact with each other.
MMT's native surface already retrieves all its dependencies from the OMDoc files anyway --- it does not even notice which format they were originally written in.

Thus, we can support the following workflows:
\begin{compactenum}
 \item MMT content is written in any format and available as OMDoc.
 \item A new interactive Notebook is written, using some of that content.
 \item The Notebook is stored as a file and MMT extracts the relevant content as OMDoc.
 \item Any other MMT document (including other Notebooks) can now use this content.
\end{compactenum}

\subsection{Graphical User Interfaces via Jupyter Widgets}\label{sec:kernel:widgets}

\ednote{Re-reference this with updated structure + diagram}

Jupyter widgets are interactive GUI components (e.g., input fields, sliders, etc.) that allow Jupyter kernels to provide graphical interfaces.
While the concept is general, it is most commonly used to refer to the Python-based widget library developed for the Python kernel.
A widget encapsulates state that is maintained in an instance of a Python class on the server and displayed via a corresponding Javascript/HTML component on the client.
A major advantage of our kernel design is that we can reuse these widgets directly in Scala using PY4J (in the top layer)

As our kernel's intelligence is maintained in MMT and thus Scala, we had to write some middle layer code to allow our kernel to create widgets.
This code uses Py4J to expose the widget-management functionality of the top layer to the lower layers.
This is done via a class of callback functions $C$ that are passed along when the former calls the latter.

\begin{figure}[ht]\centering
  \includegraphics[width=12cm]{../D4.11/ArchitectureDiagram}
  \caption{
    Architecture diagram.
    Steps that simply forward data from one layer to the next are not shown explicitly. 
  }\label{fig:architecture-diagram}
\end{figure}

Figure~\ref{fig:architecture-diagram} shows the details of the communication.
The upper part shows the simplest (widget-less) case: MMT content is entered in the frontend and forwarded to the bottom layer, and the response is forwarded in the opposite direction. 

The lower part shows a more complex widget-based interaction.
First of all, we add special management commands that are not passed on to the GUI-agnostic bottom layer.
Instead, they are identified by the middle layer, which responds by delegating to a GUI application.
This application then builds its graphical interface by calling the callbacks passed along by the top layer.
This results in a widget object in Python that is returned to the top layer and then forwarded to the frontend.

As usual, GUI components may themselves carry callback functions for handling events that are triggered by user interaction with the GUI in the frontend.
While conceptually straightforward, this leads to an unusually deep nesting of cross-programming language callbacks.
When creating a widget, the Scala-based GUI application may pass Scala callbacks whose implementation makes use of the callbacks provided by the top layer.
Thus, a user interaction triggers an MMT callback in the Python top layer, which is executed on the Scala side via Py4J, which in turn may call the Python callbacks exposed via Py4J.

Our design makes it very easy to build and deploy simple GUI applications for MMT --- we still have the full power of Jupyter widgets at our fingertips.

\paragraph*{Example: In-Document Computation}
\ednote{TW: Need to still update this}
We present a simple example of a GUI application for in-document computation.
It is triggered by the special command \texttt{active computation} and builds a GUI consisting of a few standard Jupyter widgets: a label, a button (labeled \textit{compute}), three text input fields, and one button widget.
A concrete example can be seen in Figure~\ref{fig:ac}.
This shows a notebook in which our application is returned as the response to cell \texttt{In[1]}.


\begin{figure}[ht]\centering
  \includegraphics[width=15cm]{../D4.11/activecomp}
  \caption{Active Computation in Jupyter Notebooks via Jupyter/MMT Widgets}\label{fig:ac}
\end{figure}
\ednote{TW: New screenshot}

\ednote{TW: Generalize}
The three text input fields contain values linked by an equation, in this case $E=mc^2$.
The user can edit these fields and press the button to compute the other values.
In that case, a the button carries the callback $D$, which results in a call to our application on the Scala side.
It uses MMT to perform the computation and then calls the $C$ callbacks to update the values in the widgets.
No additional work is needed to implement the synchronization between the Python top layer and the HTML frontend as this is a standard feature of Jupyter widgets.

%%% Local Variables:
%%% mode: latex
%%% mode: visual-line
%%% fill-column: 5000
%%% TeX-master: "paper"
%%% End:

%  LocalWords:  Jupyter newpart textbf ednote centering texttt includegraphics synchronized customizable inparaenum Realizing subsubsection serialized emph emph emphasizes xeus xwidgets textit activecomp synchronization
