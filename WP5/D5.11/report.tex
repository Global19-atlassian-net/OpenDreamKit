\documentclass{deliverablereport}
\usepackage{hyperref}

\deliverable{hpc}{sage-HPCcombi}
\deliverydate{31/08/2018}
\duedate{31/08/2018 (M36)}
\author{V. Delecroix, F. Hivert}

%\usepackage[nottoc, notlof, notlot]{tocbibind}
\usepackage[backend=bibtex]{biblatex}
\addbibresource{report.bib}
\makeatletter\def\blx@maxline{77}\makeatother

\usepackage{multirow}
\usepackage{xcolor,colortbl}
\usepackage{pgfplots}

\usepackage{tikz}
\usepackage{ulem}

\newcommand{\Cilk}{\texttt{Cilk}\xspace}
\newcommand{\CilkP}{\texttt{Cilk++}\xspace}
\newcommand{\CPP}{\texttt{C++}\xspace}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\sgnode}[1]{{\bf \left<#1\right>}}
\newcommand{\gr}[1]{{\color{gray} #1}}

\DeclareMathOperator{\Irr}{Irr}

\newtheorem{defi}{Definition}
\newtheorem{prop}{Proposition}


\setcounter{tocdepth}{1}
\begin{document}
\maketitle

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Computer experimentations in discrete mathematics, in particular
enumerative and algebraic combinatorics, require high performance
computing. The search spaces are often huge and the best algorithmic
strategy for the exploration is not evident and often depend on
the answer to the question being probed. Let us cite the following description
from~\cite{LoidlTrinder-Hecke}:
\begin{quote}{}
  Some discrete mathematical problems are embarrassingly parallel, and this
  has been exploited for years even at Internet scale, \emph{e.g.} the “Great
  Internet Mersenne Prime Search”.  Many parallel algebraic computations
  exhibit high degrees of irregularity, at multiple levels, with numbers and
  sizes of tasks varying enormously (up to 5 orders of magnitude). They tend
  to use complex user-defined data structures, exhibit highly dynamic memory
  usage and complex control flow, often exploiting recursion. They make
  little, if any, use of floating-point operations.  This combination of
  characteristics means that symbolic computations are not well suited to
  conventional HPC paradigms with their emphasis on iteration over floating
  point arrays.
\end{quote}

This deliverable is about experimentations in combinatorics
that involve low-level optimization and parallelization as
well as the integration of these techniques in the computer
algebra system \Sage.

This deliverable has greatly benefited from the \ODK development
workshops \textit{Sage Days 84} held in Olot (Spain) in spring 2017
and \textit{Interfacing (math) software with low level libraries}
held in spring 2018 in Cernay-la-Ville (France).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Two examples from algebra}

To compare computation technologies, our approach was to experiment
them on various problems that require intensive computations. We present two such problems.

\subsection{Counting and enumerating integer vectors}
\label{subsec:intro:integer:vectors}

Integer vectors, that is finite sequences of integers, are central
in combinatorics as they can be used to encode many different
objects. In each situation the integer vectors are subject to various
constraints and we will be interested in three different kinds:
\begin{itemize}
\item linear constraints (e.g. lower or upper bounds on the entries,
maximum differences between adjacent positions, etc.)
\item restrictions on the content (e.g. each value should be used
at most once)
\item symmetries (e.g. lexicographically smallest among all possible
cyclic permutations).
\end{itemize}
One algorithmic problem combinatorics is trying to solve is to provide
efficient enumeration of integer vectors subject to these kind of
constraints.

For example, permutations of $\{1, \ldots, n\}$ are encoded by integer vectors
on $\{1, \ldots, n\}$ for which each entry appear exactly once. In a sample
\Sage session the list can be obtained as follows:
\begin{verbatim}
sage: P = Permutations(3)
sage: P.list()
[[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1],
 [3, 1, 2], [3, 2, 1]]
\end{verbatim}
Other elementary examples include integer partitions
\begin{verbatim}
sage: Partitions(5).list()
[[5], [4, 1], [3, 2], [3, 1, 1], [2, 2, 1], [2, 1, 1, 1],
 [1, 1, 1, 1, 1]]
\end{verbatim}
or Lyndon words
\begin{verbatim}
sage: LyndonWords(2,4).list()
[word: 1112, word: 1122, word: 1222]
\end{verbatim}

Sometimes, one just wants to count the number of objects in some set and possibly
avoid generating the complete list. In \Sage, access to this
counting is often implemented by a {\tt cardinality()} method, the
implementation of which can be often be different from the implementation for
enumerating the objects themselves:
\begin{verbatim}
sage: Permutations(30).cardinality()
265252859812191058636308480000000
sage: Partitions(1000).cardinality()
24061467864032622473692149727991
sage: LyndonWords(2, 120).cardinality()
11076899964874298931257370467884546
\end{verbatim}

In this deliverable we will demonstrate how the interface to the LaTTe package
in \Sage allows more efficient counting and how Cython has helped faster enumeration
in \Sage. We will also present some promising experiments involving among
other things vectorization techniques (MMX, SSE and AVX instruction sets) and
shared memory multicore computing with \CilkP.

\subsection{Numerical semigroups}

A computation involving numerical semigroups  is known as Frobenius coin
problem. Given a set of coins of specifified denominations, it asks what is
the largest monetary sum that {\em cannot} be obtained using only coins in that
set. Formally,
\begin{defi}
  A \emph{numerical semigroup} $S$ is a subset of $\NN$ containing $0$, closed
  under addition and of finite complement in $\NN$.
\end{defi}
For example the set $S_E=\{0,3,6,7,9,10\}\cup\{x\in\NN, x\geq 12\}$
is a numerical semigroup. One of the challenging problems in the field of
semigroup analysis is to understand how many numerical semigroups there are with some
given constraints. To state the question precisely we need a little
terminology:
\begin{defi}
  Let $S$ be a numerical semigroup. We call the \emph{genus} of $S$ the
  cardinality of the complementary set $g(S)=\operatorname{card}(\NN\setminus
  S)$.
\end{defi}
For example the genus of the previous example $S_E$ is $6$, the cardinality of
$\{1,2,4,5,8,11\}$.

For a given positive integer $g$, the number of numerical semigroups of genus
$g$ is finite and is denoted by $n_g$. In J.A. Sloane's \emph{on-line
encyclopedia of integer sequences}~\cite{OEIS} we find the values of $n_g$
for $g\leq 52$. These values were obtained by M. Bras-Amor\'os~\cite{BrasAmoros2008}. It is conjectured that the number of
those semigroups grows exponentially with the genus $g$. So it makes it both interesting and hard
to get further values of $n_g$ by directly enumerating semigroups.

Using adequate data structures and parallelization with \Cilk allowed
F.~Hivert with his collaborator J.~Fromentin to obtain the number of numerical
semigroups up to genus $g \leq 70$ and also to confirm for $g\leq 60$ another
unrelated famous conjecture due to Wilf~\cite{Wilf}. This work has led to the
publication~\cite{FromentinH16}.

We would like to explain why exploring this tree is quite challenging as a
parallel problem. The computation for $g=70$ involves exploring an extremely
large tree with $10^{15}$ nodes. Of course, when exploring such a tree,
different branches can be explored in parallel. However, if the tree is
unbalanced, we need a mechanism to rebalance the computation. It appears that
the tree of numerical semigroups is extremely unbalanced and is therefore a good
prototypical challenge for such a computation. For example, } the number of nodes at depth 30 and 45
are $5\,646\,773$ and $8\,888\,486\,816$ respectively. If we sort the nodes
at depth $30$ decreasingly by their number of descendants at depth $45$, then
\begin{itemize}
\item The first node has $42\%$~of the descendants;
\item The second node has $7.5\%$~of the descendants;
\item The $1000$~first nodes have $99.4\%$~of the descendants;
\item Only $27\,321$ nodes have descendants at depth~$45$;
\item Only $257$ nodes have more than $10^6$~descendants.
\end{itemize}
As a consequence, any
naive embarassingly parallel algorithm is doomed, as the majority
of the time may be spent in just a few branches. There must be
some non-trivial load balancing to achieve good performance.  We will discuss the
different technologies to solve this problem.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
\subsection{Classes of problems appearing in algebra and combinatorics}

In our experiments, we have identified the following four kinds of problems:
\begin{enumerate}
\item\label{enum-flat} \emph{Embarrassingly parallel problems}: where
  little or no effort is needed to separate the problem into a number of
  parallel tasks.
\item\label{enum-tree} \emph{Recursive parallel problems}: the computational
  problem is organized as a recursive tree which can be discovered on the fly
  during the computation.
\item\label{enum-graph} \emph{Recursive redundant parallel problems}: this
  kind of problem is similar to the previous one except that instead of a
  tree, the computational problem is organized as a (directed acyclic) graph
  so that they are multiple different way to reach the same computation. So the
  computing units have to coordinate to avoid recomputing the same thing too
  many times or to detect that all the prerequisites for a task are known.
\item\label{enum-micro} \emph{Micro data structure parallel optimization}:
  for many combinatorial structures (permutations, partitions, monomials, Young
  tableaux), their data can be encoded as a small sequence of small integers
  that can often be be handled efficiently by a CPU thanks to vector instructions.
\end{enumerate}
In this work we have mostly focused on point (\ref{enum-tree}) and
(\ref{enum-micro}) as (\ref{enum-flat}) is easy and (\ref{enum-graph}) cannot
be solved without a good solution for (\ref{enum-tree}) which is still
problematic.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{An overview of techniques and technology}

Before going deeper into the details of this deliverable it is important to
draw a general picture of the algorithmic techniques and the hardware and
software technologies available.

Let us first distinguish the following two families of programming
languages. On the one hand there are the interpreted languages
such as \Python or Julia. On the other hand we have the compiled languages
such as C/C++. The former languages are very convenient for end-users as
they provide high level data structures and instructions as well as automatic
memory management. This is one of the reasons for the choice for \Python as the
base language for \Sage. However, these higher level languages tend to suffer
by comparison to low-level languages in performance, especially when large
iterations have to be performed. In this situation, it is necessary to
investigate the details of memory allocation and CPU instructions. 

A first ingredient of optimization that provides a bridge between interpreted
and compiled language is provided by \Cython, a Python
to C/C++ compiler. \Cython plays an important role in this deliverable in two
different ways. First, by replacing Python code with Cython code, which generally results
immediately in faster code. Second, by developing interfaces to C/C++ libraries.

The use of a low-level language such as C/C++, provides the programmer with a
first level of in-core
parallelization: the CPU vectorized
instructions, i.e. single instructions operating on vectors of multiple
data (SIMD). These instructions are also of critical importance for efficient
linear algebra algorithms as implemented in the \Linbox library. The relevance
of these instructions in the context of combinatorics is discussed in
Section~\ref{subsec:combi:SIMD}. 

The second level of parallelization concerns multi-core computations. This is
conveniently dealt with by language extensions such as Open MP, Threading 
Building Block (TBB) or \Cilk. At this level one important ingredient in
optimization is the careful usage of shared memory.  Before getting into
technical details, we recall in subsection~\ref{subsec:map-reduce:Sage} the
small framework that was implemented in \Sage
during~\longdelivref{hpc}{sage-paral-tree} that also illustrates the typical
problem one faces in combinatorics. More details on the usage of \Cilk are
provided in Section~\ref{sec:low:level}.

The last level of parallelism concerns computations with multiple nodes
(e.g.~multiple computers on a network) and is not addressed by this
deliverable.

\subsection{Map-reduce and its implementation in \Sage}
\label{subsec:map-reduce:Sage}

The aim of this section, is to present an example of a typical end-user feature we would like
to be able to provide as an actual HPC component. This is a solution for
type~(\ref{enum-tree}) problems in our classification.

Map-reduce is a general programming model that is shared by
parallelized solutions to many problems and is relevant to our situation. In this section we
present a small framework implemented in Sage~\cite{sage} which enables
efficient map/reduce-like computations on
large recursively defined sets. Map-reduce is a classical programming model
for distributed computations where one maps a function on a large data set --
applying the same function to each element of the data set -- then
uses a ``reduce'' function to summarize all the ``map'' results. It has a
large range of intensive applications in combinatorics:
\begin{itemize}
  \item Compute the cardinality;
  \item More generally, compute any kind of generating series;
  \item Test a conjecture: i.e. find an element of $S$ satisfying a specific
    property, or check that all of them do;
  \item Count/list the elements of $S$ having this property.
\end{itemize}
Use cases in combinatorics often have two specificities. First of all, due to
combinatorial explosion, sets often don't fit in the computer's memory or
disks and are enumerated on the fly. Then, many problems are flat, leading to
embarrassingly parallel computations which are easy to parallelize. However, a
second very common use case is to have data sets that are described by a
recursion tree which may be heavily unbalanced (as with numerical semigroups
described in the previous section).

The framework~\cite{map-reduce} we developed works on the following input:
A \textbf{recursively enumerated set} given by:
\begin{itemize}
\item the \texttt{roots} of the recursion
\item the \texttt{children} function computing the next level of the recursion
\item the \texttt{post\_process} function, which can also filter intermediate nodes
\end{itemize}
Then, a \textbf{map-reduce problem} is given by:
\begin{itemize}
\item the \texttt{map} function
\item the \verb|reduce_init| function, which specifies an initial value for
    the reduction process
\item the \texttt{reduce} function
\end{itemize}
Here is an example where we count binary sequence of length 15:
\begin{verbatim}
sage: S = RecursivelyEnumeratedSet( [[]],
....:   lambda l: [l+[0], l+[1]] if len(l) <= 15 else [],
....:   post_process = lambda x : x if len(x) == 15 else None,
....:   structure='forest', enumeration='depth') 
sage: sage: S.map_reduce(
....:   map_function = lambda x: 1,
....:   reduce_function = lambda x,y: x+y,
....:   reduce_init = 0 )
32768
\end{verbatim}
This framework uses a multi-process implementation of a work-stealing
algorithm~\cite{BlumofeL99, BlumofeL99} meaning that if work is divided
unevenly between processes, when one process becomes idle it can ``steal'' new
work to do from another process's work queue. On the above example of binary
sequences it scales as follows
\[\begin{tabular}{ccccc}
\# processors & 1 & 2 & 4 & 8 \\
Time (s) & 250 & 161  & 103  & 87 \\
\textcolor{red}{Speedup}
 & \textcolor{red}{1}
 & \textcolor{red}{1.55}
 & \textcolor{red}{2.42}
 & \textcolor{red}{2.87}
\end{tabular}
\]
As can be seen on this sample the scaling is far from
being linear with the number of cores. This is explained by the increase
of job stealing coming with parallelization. A challenge will be to reduce
this overhead and achieve linear scaling.

Though it doesn't really qualify as HPC, principally due to the use of Python.
Tough it allowed us to efficiently parallelize dozens of experiments ranging from
Coxeter group and representation theory of monoids, to the combinatorial study
of the C3 linearization algorithm used to compute the method resolution order
(MRO) in scripting languages such as \Python and Perl~\cite{C3-controled}.

\section{Low-level experiments}
\label{sec:low:level}

We now present the result of the evaluation of various parallelization
technologies applied to algebraic combinatorics computations.

\subsection{Combinatorial structures and vector instructions}
\label{subsec:combi:SIMD}

Current SIMD instruction sets were introduced
in three stages: MMX (set of single instruction multiple data instruction set
introduced in 1997), SSE (Streaming SIMD Extensions, introduced in 1999) and
more recently AVX (Advanced Vector Extensions, introduced in 2008).

In many combinatorial structures (permutations, partitions, monomials, Young
tableaux), the data can be encoded as a small sequence of small integers that
can often be handled efficiently thanks to these vector instructions. For
example, on current desktop CPU architectures ({\texttt x86}), small
permutations ($N\leq 16$) are very
well handled. Indeed, thanks to machine instructions such as \verb+PSHUFB+ (Packed
Shuffle Bytes), applying a permutation on a vector only takes a few CPU cycles.  Here
are some examples of operations with their typical speedups via SIMD instructions:
\[
\begin{tabular}{l|c}
Operation & Speedup \\\hline
Sum of a vector of bytes & $3.81$\\
Sorting a vector of bytes& $21.3$\\
Inverting a permutation& $1.97$\\
Number of cycles of a permutation& $41.5$\\
Number of inversions of a permutation& $9.39$\\
Cycle type of a permutation& $8.94$\\
\end{tabular}
\]
Unfortunately, from a developer's point of view, this requires rethinking all
the algorithms, and there is nearly no support from the compiler for
automating this task.\bigskip

As a part of the OpenDreamKit deliverable, we started to develop a new
library called \texttt{HPCombi}\footnote{\url{https://github.com/hivert/HPCombi}}. The
goal is to use SSE and AVX instruction sets for very fast manipulation of
combinatorial objects of small sizes.  It is still in an experimental stage and
currently deals only with permutations, transformations and partial
transformations. We also have experimental code for partitions and boolean
matrices.

Despite its infancy the code is already used by
libsemigroups~\cite{libsemigroups} (which deals with a different kind of
semigroup from numerical semigroups) by James Mitchell. It is a C++ library
for semigroups and monoids using C++11, and is used in the Semigroups package
for GAP. The development version is available on \GitHub, and there are Python
bindings which makes it usable from \Sage. The development of a more thorough
\Sage interface is planned.  \bigskip

Finally, we want to stress out that this is actually a research
problem. Indeed, except for sorting a vector where we used a classical sorting
network algorithm, all the operations in the previous table of operations
require the design of a new algorithms as nearly no combinatorial algorithms
where conceived of with vector instructions in mind. For example, for the
simple task of inverting a permutation, we designed 4 different new
algorithms:
\begin{itemize}
\item \verb|inverse_sort|:  a classical sort algorithm
\item \verb|inverse_search|:  using parallel binary
  search. Limited by the current size of vector registers ($16$~bytes) which support
  arbitrary array manipulation (in particular the shuffle instruction), it is
  not the fastest algorithm. Yet it is the only one of {\em logarithmic} complexity,
  so it should become the fastest if and when a CPU supporting larger registers
  for this instruction become available;
\item \verb|inverse_power|: a binary powering algorithm;
\item \verb|inverse_cycle|: using the cycle decomposition. It is currently the fastest.
\end{itemize}
Preliminary results from this work were presented as a keynote invited talk at
the 8th International Workshop on Parallel Symbolic Computation (PASCO 2017),
Kaiserslautern, Germany, July 23-24, 2017 and at the Scottish Programming
Languages Seminar, 5th June 2018, Heriot-Watt University. A research paper on
this subject is in preparation as a result of this work.

\subsection{Combinatorial structures and GPU computations}

In the previous section we presented how the vector instruction of modern
CPUs enabled a large speedup for small combinatorial objects. The main
requirement is that the datastructure fits in one or a
handful of the CPU registers (data storage areas internal to the CPU, where
intermediate results of computations are stored). However, while this
covers a lot of practical case on algebraic combinatorics,  there is sometimes a
need for larger combinatorial objects, due to combinatorial
explosion. One lead was to investigate if graphics
processing units (GPUs) could speed up these kinds of computations. Our benchmark was to write a
toy implementation of the algorithm used in libsemigroups~\cite{libsemigroups}
replacing the use of HPCombi and AVX CPU vector instruction by some GPU
code. These algorithms enumerate the elements of a transformation of semigroups.

This kind of computation typically involves the repetition of two computation
stages:
\begin{enumerate}
\item compute the composition of large functions on a discrete set;
\item store them in a hash table to remove duplicates.
\end{enumerate}
It should be noted that the first stage doesn't require any arithmetic, but
amount to shuffling around large chunks of data in memory. This is a very atypical usage of a
GPU which is tailored to do arithmetic on larger vectors of floating point numbers, and it was very difficult
to predict the behavior. One expected cause of this inconsistency is the communication time
between the CPU and the GPU.
\medskip

The outcome of the experiments lead by Daniel Vanzo (research engineer at
LRI/UPSud) under the supervision of Florent Hivert were that:
\begin{itemize}
\item Composition of large functions can be greatly accelerated (typically
$\times 100$) by the GPU, \emph{provided} that the CPU ask the GPU to perform
enough of them (more than 1K) at once.
\item The same is true for the computation of hash values.
\end{itemize}
Although this requirement seems reasonable for the first stage, it is not for
the second: in a reasonable use case, one needs to store the results of the
computation in a large hash table which typically is at the limit if not
larger than the size of the GPU's memory. We  therefore decided to keep the hash table
in the computer's main memory, external to the GPU, degrading performance due
random memory accesses. Nearly all
memory accesses triggered a cache miss which resulted in slowdown of as much as
$60\times$. \bigskip

The conclusion is that in order to achieve a useful speedup with the GPU, the entire computation
must be hosted inside the GPU's internal memory. This has two very important drawbacks:
\begin{itemize}
\item It drastically limits the size of the computation as CPU memory tends to
  be around $10\times$ larger than the GPU's.
\item Since GPU programming is not a widespread skill, it forces us to write
  seemingly black-box, monolithic algorithms.
\end{itemize}
This second point doesn't fit well within the research-driven use case
typical of the OpenDreamKit project; that is, it is difficult to understand
or modify by a typical researcher. % Note: I added an additional clause here, clarifying what I think you meant.
We think this technology is not directly applyable for algebraic combinatorics
in general but  is only  interesting
for very specific computations where we are ready to pay the price of developing a large
specific and poorly reusable code.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% \subsection{Integer vectors up to permutations}
% \label{subec:integer:vectors}

% We briefly report a successful optimization using the technologies
% evoked in the previous section. The aim was to optimize an algorithm
% developed by N.~Borie for enumerating integer vector modulo permutation
% groups~\cite{Borie}.

% The problem is the following: we are given a subgroup $G$ of the symmetric
% group $S_n$. It acts by permutation of coordinates on the vectors in $\NN^n$.
% The problem is to generate one vector in each orbit. Note that there are
% infinitely many such vectors; in practice one usually wants to enumerate the
% vectors with a given sum or content. 

% N.~Borie designed a tree structure on those vectors which allows to enumerate
% them recursively. At the level of each node, a relatively complicated
% computation is done involving partial lexicographic comparison and a hash
% table to avoid some duplication. The goal was to optimize the particular case
% of small groups where $n\leq16$. The development went along the following
% steps:
% \begin{itemize}
% \item permutation, vectors and lexicographic comparison using vector
%   instructions;
% \item recursive enumeration using \CilkP
% \item used thread local strorage for the hash table at the level of each node
% \item designed a handmade hash table to avoid dynamic allocation and adapted
%   to the specific use-case
% \end{itemize}
% This last step is due to a very specific use case for the hash table: we
% needed it to store a dynamic set where we only add elements and never remove
% one, and we clear the hash table very often. Profiling showed that the hash
% table may grow up to thousand of elements but, on the average, is
% only cleared when containing $2.5$~elements ! We decided therefore to use a
% closed bounded hash table together with a linked list of used buckets to be
% able to clear the table quickly.

% Altogether, we compared our optimized version with an already optimized
% non-parallel compiled version using the \Python compiler Cython. Computing the
% $375810$~integer vectors of sum 25 for the largest transitive subgroup of
% $S_{16}$ took $9$min $23$s on a single core with Sage's code, whereas our code
% is able to do it in $0.503$s on $8$~cores for a speedup of $1112$ times.
% Finally, the code (not yet released) is downloadable at~\cite{IVMPG}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Numerical semigroups}
\label{subsec:numerical-semigroups}

The computation of numerical semigroup is a good challenge for large tree
explorations (case (\ref{enum-tree}) in our
classification). This kind of problem is classical and can they can be solved by
various technologies. The idea here is that different branches of the
tree can be explored in parallel by different CPU cores. The
delicate part is to ensure that all cores can be provided with tasks,
i.e. always having a new branch to explore.

What makes combinatorics particularly difficult is the size of the
trees (typically up to $10^{15}$ in our experiments) and the granularity of the
computation (typically only $10-50$ns is spent on each tree node). This is
extremely demanding on the load balancing algorithms and their implementations.

The clear algorithmic solution is to use work stealing algorithms as described
described in \cite{10.1109/SFCS.1994.365680, BlumofeL99}. We have developped a 
Python implementation with a map-reduce fronted
in Deliverable~\delivref{hpc}{sage-paral-tree}~\cite{map-reduce}. However, it
was clear from the beginning that this 
implementation was a tool to help rapid prototyping in day-to-day research,
but it wasn't meant for a high performance computing use case. So we experimented
with a few lower-level technologies. We present them here together with their
behavior in our prototypical examples:
\begin{itemize}
\item The \CilkP~\cite{CilkIntel} technology is particularly well suited for
  those kinds of problems. For our computation, we used the free version which
  is integrated into the GNU~C compiler~\cite{GCCcilk} since version 5.8.

  \Cilk is a general-purpose language designed for multithreaded parallel
  computing. The \CPP incarnation is called \CilkP. The main principle
  behind the design of the \Cilk language is that the programmer should be
  responsible for \emph{exposing} the parallelism, identifying elements that
  can safely be executed in parallel; the run-time environment decides during
  execution how to actually divide the work between CPU cores. The parallel
  features of \CilkP are used mainly through the \texttt{cilk\_spawn} keyword:
  used on a procedure call, it indicates that the call can safely operate in
  parallel with the remaining code of the current function. Note that the
  scheduler is not obliged to run this procedure in parallel; the keyword
  merely alerts the scheduler that it can do so.

  Overall, this makes \CilkP very easy to use, with short and very readable
  source code. Moreover, it turns out that \CilkP is extremely good at solving
  the problems we were interested in. To provide some figures of the performance we managed
  to achieve in counting monoids--a problem similar to that of counting
  semigroups. We performed a full exploration of the tree up to a depth of~$70$ on
  a $32$~core Haswell CPU at $2.3$~Ghz. The number of monoids at depth $70$ is
  $1607394814170158$.  It tooks $2.528\cdot10^{6}~s$ ($29$~days and $6$~hours)
  exploring $2590899247785594=2.59\cdot10^{15}$ monoids at a rate of
  $1.02\cdot10^{9}$ monoids per second. Each monoid is stored in
  $240$~bytes. Storing all the computed monoids would take
  $6.22\cdot10^{17}$~bytes of data, which means that we generated
  $2.46\cdot10^{11}$~bytes of data per second.

  The main drawback, is that both Intel and the GCC team decided
  to \textbf{deprecate and no longer maintain the \CilkP extension}. So we
  looked for alternatives.


\item \emph{OpenMP} (Open Multi-Processing) is an application programming
  interface (API) that supports multi-platform shared memory multiprocessing
  programming in C, C++, and Fortran. It consists of a set of compiler
  directives, library routines, and environment variables that influence
  run-time behavior. It allows to spawn tasks using special pragma directives on the
  compiler.

  Unfortunately, for computations like numerical semigroups, there
  is a huge number of small tasks that are spawned. We used the implementation
  from the GCC compiler. At the time of our experiment, we found that the
  scheduler doesn't scale to this huge number of tasks required. The scheduling overhead
  was several order of magnitude larger than \CilkP making it unusable for
  these kinds of computations.

\item Intel's \emph{Threading Building Blocks} is a C++ template library
  developed by Intel for parallel programming on multi-core processors. Using
  TBB, a computation is broken down into tasks that can run in parallel. The
  library manages and schedules threads to execute these tasks.

  However, it suffers exactly the same problem as OpenMP: the scheduler
  doesn't scale for huge numbers of tasks. Intel's FAQ reads, ``A good rule of
  thumb is that an Intel TBB application should have approximately 10 tasks
  for every worker.'' Similarly, in \cite{LuLi}, they consider a problem
  requiring micro-task computations of roughly 30k tasks, each of which takes 4k
  CPU cycles. Whereas in the numerical monoid problem task takes around 60
  CPU cycles, the number of tasks easily exceeds 1 billion for a 1 minute long
  computation.

\item Developping efficient scheduler able to deal with very large amount of
  lightweight tasks is an active research area. For instance the ongoing PhD
  thesis by Blair Archibald under the supervision of Phil Trinder at University
  of Glasgow exactly also aims to distribute the computation on a cluster
  of machines. As a result, they developed a C++ library called
  YewPar~\cite{YewPar} which they present as ``A Collection of High
  Performance Parallel Skeletons for Tree Search Problems'' using the well
  established HPX~\cite{HPX} parallel library/runtime.

  By the time we got in contact with them, they had already decided to use our numerical
  semigroup algorithm as a benchmark for their scheduling implementation. We
  think that this is a good indication that our choice was correct. Though not
  as easy as \CilkP, the YewPar's integration
  provides distribution across several machines. If only used on
  one multicore machine, YewPar is more or less only $2.5$ times slower than
  \CilkP. The main question is long term maintenance: the website says ``This
  library is currently experimental and should be considered very unstable,''
  and being the work of a PhD student, there is no warranty that it will
  still be maintained in a few years.

\item We also advised three master student interns; namely, Adrien Pavão,
  Thomas Foltête, and Edgar Fournival to explore the Spark technology and the
  Go language. It turned out that these technology weren't fit for our
  needs. On the other hand, their work led to discovery of a basic bug in the GCC
  implementation of \CilkP \cite{gcc-bug-80038}.
\end{itemize}

In conclusion, for large combinatorial tree explorations our current
recommendation is to use \CilkP which is both very efficient and simple to use
and learn. We hope that an eventual alternative will manage to achieve similar
performance. A promising newcomer is the Cilk Hub initiative\footnote{\url{http://cilk.mit.edu/}}
to continue maintaining Cilk under a new project, but we have not yet had ocassion to seriously
experiment with it.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Improvements to the \Sage platform}


\subsection{Polytopes and linear programming}
\label{subsec:polytopes}

As mentioned in the introduction, see~\ref{subsec:intro:integer:vectors},
integer vectors are omnipresent in combinatorics. In many situations,
the combinatorial constraints are linear equalities or inequalities.
For example, the partitions of $n$ are given by non-negative integer
vectors $(x_1, \ldots, x_n)$ in $\mathbb{R}^n$ so that $x_1 \geq x_2 \ldots x_n$.
In other words, some general linear programming techniques come into
play. Improving \Sage's capabilities in polytope computations and linear algebra
is critical for combinatorics.

Many libraries, often written in C/C++ exist and one of our tasks was to
create or improve the existing \Sage interfaces to those libraries. Most of these interface
rely on Cython to provide a bridge between \Python and C/C++. Let
us mention the creation of the stand-alone library pplpy~\cite{pplpy-code} which now provides
access to the PPL library to any Python user, and is integrated into \Sage.

At a higher level of interaction, an interface to LaTTe in \Sage has
been developed (see trac tickets~\cite{trac-18211}
and~\cite{trac-22497}). It allows efficent counting of
integral points in polytopes. The interface is completely transparent to the
user as can be seen in the following Sage session:
\begin{verbatim}
sage: n = 10
sage: I1 = [[0] + [0]*i + [1] + [0]*(n-1-i)
....:       for i in range(n)]
sage: I2 = [[0] + [0]*i + [1,-1] + [0]*(n-2-i)
....:       for i in range(n-1)]
sage: P = Polyhedron(ieqs=I1 + I2, eqns=[[-n] + [1]*n])
sage: P.integral_points_count()
42
\end{verbatim}
Let us also mention the \Sage interface to the Polymake
software~\cite{polymake-code} which allows direct interaction from
\Sage. Polymake is a reference software for Polyhedral computations
and its inclusion in \Sage has been greatly beneficial.

Polyhedral computations are not restricted to rational numbers. For a long time
floating point polyhedral libraries have existed. However, they are often not
satisfactory, as floating-point rounding errors can lead to subtle contradictions. In the framework
of \ODK, V.~Delecroix started a C/C++ library for computations with embedded
number fields called e-antic~\cite{eantic-code}. It allows exact computations
over algebraic numbers. This has successfully been included in the
Normaliz~\cite{normaliz-code} software and it is now possible to use
it to very efficiently construct polytopes over number fields. We aim to
finalize the inclusion of this code and provide a \Sage interface to it.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Cythonization of combinatorics code}

A huge amount of code in \Sage is written in plain Python; this is in
particular true for a large amount of the combinatorics code. Thanks to
Cython, one can easily gain speed-up in computations. A lot of effort has
been made to improve the performance of the current code. We emphasize
some of the efforts that has been made in \ODK.

Two examples of successful ``cythonization'' were achieved for
permutations~\cite{trac-23734} and Lyndon words~\cite{trac-26111}.
These combinatorial objects were already mentioned in the
introduction; see~\ref{subsec:intro:integer:vectors}.
The challenge was to write iterators with maximal efficiency
together with a simple Python wrapper intended for \Sage users.
While in both situations presented here, efficient algorithms exist
we have focused on three levels of optimization:
\begin{itemize}
\item \textit{basic cythonization}. Cython does a decent job in
direct optimization with little human intervention. 
\item \textit{in-place iteration}. As already mentioned, combinatorial objects are typically represented by
integer vectors. Dealing with a lot of plain lists in Python has a huge
cost in memory allocation. The most natural workaround is to provide an in-place
iterator, that is, an iterator that modifies the data without creating new objects.
\item \textit{use C arrays}. Finally, using a Python data structure closer to C
arrays than Python's built-in ``list'' type allows one to gain another speedup factor.
\end{itemize}
Below we present simple timings of the iteration through all permutations
of $\{1, 2, \ldots, n\}$ with three runs of the same algorithm. It consists
in modifying a given permutation into the next one for the lexicographic
order. The three columns represent the different versions: in Python
using Python lists, in Cython using Python lists and finally in Cython
using C arrays.
  \begin{center}
\begin{tabular}{c|c|c|c}
    n & Python & Cython on lists & Cython on arrays \\
\hline
9  & 410ms   & 55ms  & 37ms \\
10 & 2.9s    & 309ms & 163ms \\
11 & 32s     & 3.2s  & 1.68s \\
12 & $>$ 2 min & 36.3s & 19.5s \\
\end{tabular}
  \end{center}
These experimets show a near 10x speedup when passing to Cython (with almost no
modification), then Using arrays instead of lists provides an additional 2x speedup.

Let us also mention a slightly different work related to combinatorics:
Dancing links is the name of an algorithm that finds all solutions to
the so-called exact cover problem. It can efficiently be used to
solve tiling problems. Using an embarrassingly parallel method,
this naive parallelization approach allowed us to obtain the list
of solutions 2 to 3 times faster using a 4 core machine
(see~\cite{trac-25125}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}
\Sage is a general purpose computer algebra system with a lot of code related
to combinatorics. The Python language has some weaknesses regarding speed and the
aim of the deliverable was to circumvent these weaknesses. As we demonstrated,
using Cython and careful memory usage allows us to provide an
important speed up in enumeration. Cython is at the same time an ideal
tool to provide access to efficient implementations in C/C++ from Python.

Very promising experimentations have been performed in C regarding the usage
of vectorized operations (SIMD) as well as efficient parallelization. We will
pursue the development of the HPCombi library with the aim to get it
integrated into different computer algebra system such as \Sage and \GAP.

\printbibliography

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

