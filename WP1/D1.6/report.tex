\documentclass{deliverablereport}

\deliverable{management}{data-plan2}
\deliverydate{30/08/2018}
\duedate{31/08/2018 (M36)}
\author{Benoît Pilorget}

\begin{document}
\maketitle

\begin{abstract}
This document aims at gathering general information concerning data
produced within the \ODK project, and steps taken by the project to
foster its dissemination and long term preservation. Such data
includes but is not limited too:
\begin{enumerate}
\item Code, including its history and possibly social metadata (issue tracking, ...)
\item Publications
\item Databases
\item Reports, web site content, ...
\end{enumerate}
A first version of this document was produced at the occasion of
\longdelivref{management}{data-plan1}; this version was updated by
each site with the information they could provide as of August 31st of
2018. Once again, there is little Intellectual Property discussion
since, following the project's Open Source, Open Data, Open
Publication, Open Management spirit, all the data is available under
some appropriate Free (as in Free Speech) license.

\end{abstract}

\clearpage
\tableofcontents
\clearpage

\section{Project information}
\begin{itemize}
\item\textbf{Action to be implemented:}


Open Digital Research Environment Toolkit for the Advancement of Mathematics - OpenDreamKit, project number 676541
\item\textbf{Funding Programme:}


OpenDreamKit is a Horizon 2020 European Research Infrastructure project 
\item\textbf{Objective:}


It will provide substantial funding to the open source computational mathematics ecosystem, and in particular popular tools such as \Linbox, MPIR, SageMath, \GAP, \Pari/GP, LMFDB, \Singular, MathHub, and the IPython/Jupyter interactive computing environment.
From this ecosystem, OpenDreamKit will deliver a flexible toolkit enabling research groups to set up Virtual Research Environments, customised to meet the varied needs of research projects in pure mathematics and applications, and supporting the full research life-cycle from exploration, through proof and publication, to archival and sharing of data and code.
\item\textbf{Partners:}


\begin{enumerate}
\item[1-] Université Paris-Sud (UPSud)
\item[2-] Centre National de la Recherche Scientifique (CNRS)
\item[3-] Jacobs University Bremen GGMBH (JacobsUni - Terminated)
\item[4-] Université Grenoble-Alpes (UGA)
\item[5-] Technische Universitaet Kaiserslautern (UNIKL)
\item[6-] The Chancellor, Masters and Scholars of the University of Oxford (UOXF)
\item[7-] Uniwersytet Slaski (USlaski)
\item[8-] The University of Sheffield (USFD - Terminated)
\item[9-] University of Southampton (Southampton - Terminated)
\item[10-] The University Court of the University of St Andrews (USTAN)
\item[11-] Université de Versailles-Saint-Quentin-en-Yvelines (UVSQ)
\item[12-] The University of Warwick (UWarwick)
\item[13-] Universitaet Zuerich (UZH - Terminated)
\item[14-] Logilab (Logilab)
\item[15-] Simula Research Laboratory AS (Simula)
\item[16-] Universiteit Ghent (UGent)
\item [17-] European XFEL (XFEL)
\item [18-] Universität Erlangen-Nürnberg (FAU)
\item [19-] University of Leeds (ULeeds)
\end{enumerate}
\end{itemize}

\newpage
\begin{itemize} 
\item\textbf{Timeframe:}

The project lasts 48 months, from the 1st of September 2015 until the 31st of August 2019.
\end{itemize}

\section{Data responsibility}

\begin{itemize}
\item{}Every partner will be technically and legally responsible for keeping, disseminating and preserving data created within their labs, even in cases where works are led by researchers coming from various partners.
\item{}Results are owned by the beneficiary that generates them. Two or more beneficiaries own results jointly generated under the terms stated in article 26.2 of the Grant agreement.
\item{}The Research Executive Agency (referred as ‘the Agency’) may -with the consent of the beneficiary concerned- assume ownership of results to protect them up to four years after the 31st August 2019 under the terms stated in article 26.4 of the Grant agreement.
\item{}Each beneficiary must examine the possibility of protecting its results and must adequately protect them under the terms stated in article 27 of the Grant agreement.
\item{}Each beneficiary must up to four years after the 31st of August 2018 take measures aiming to ensure exploitation of its results under the terms stated in article 28 of the Grant agreement.
\item{}Unless it goes against their legitimate interests, each beneficiary must take measures as soon as possible to disseminate its results under the terms stated in article 29 of the Grant agreement.
\end{itemize}
 

Intellectual property bindings are to be found in the OpenDreamKit Consortium Agreement.
However, almost all the data creation process is directly linked to the addition of  codebase to opensource softwares. All the data creation is given open access by nature. Data for opensource softwares is furthermore preserved anc accessible on the softwares' platforms and/or repositories.
At the project level, the Coordinator will be a technical help to partners putting their data and publications on open access platforms if it is necessary.

\section{Necessary resources for implementation}
\subsection{Publications : Green and Gold access (financial resources)}


\begin{itemize}
\item{}Green access: no financial resources are required if partners choose this option for their publications
\item{}Gold access: partners who have chosen this option are free to acquire the right from publishers to edit their publications in open access.
UPSud, CNRS, JacobsUni, UJF, USFD, Southampton, USTAN, UZH, and Simula have planned gold open access publication charges in their estimated budget (CF Grant Agreement).
\end{itemize}

\subsection{Open access for data and publications (human resources)}


\begin{itemize}
\item{}Partners will use their own process with their administration to publish in open access the decided document
\item{}The Coordinator will support partners that are standing without a clear process of their own
\item{}The Coordinator will supervise ,and intervene if help needed, publication at the consortium of data and publications on European platforms.
\end{itemize}


\subsection{Data without open access}
\begin{itemize}
\item{}No specified resources were planned at this stage.
\item{}All data created and managed by OpenDreamKit participants are open access.
\end{itemize}
\newpage
\section{Datasets}
All the following datasets are public and accessible via open access platforms and/or softwares.


\subsection{Website}

\begin{description}
\item[Data storage and security] The website is located on Github: \href{https://github.com/OpenDreamKit/OpenDreamKit.github.io}{https://github.com/OpenDreamKit/OpenDreamKit.github.io}
\item[Dissemination] This dataset is the main dissemination tool of OpenDreamKit, and therefore disseminates itself
\item[Preservation] By using the distributed system git to manage most of our data, we assure a local copy of the data within each participant machine. We rely on the Github external platform for public access. If it should happen that this platform is not available any more, the data can easily be moved away to another platform.
\begin{itemize}
\item\textit{Name of data} The OpenDreamKit website
\item\textit{Nature of data} Text and metadata concerning OpenDreamKit participants and activities
\item\textit{Reuse of existing data} Data such as status reports are accessible to the all opensource software communities so they can follow the evolution of the project. 
\item\textit{Mean of production} Written by OpenDreamKit participants
\item\textit{Data standard} Source code is written in Markdown language and converted into html.
\item\textit{Link} \href{http://opendreamkit.org/}{opendreamkit.org}; \href{https://github.com/OpenDreamKit/OpenDreamKit.github.io}{https://github.com/OpenDreamKit/OpenDreamKit.github.io}
\end{itemize}
\end{description}

\subsection{Additions to \Sage codebase}


\begin{description}
\item[Data storage and security] All addition to the \Sage codebase will be stored within the distributed \Sage repository on the trac server \href{http://trac.sagemath.org/}{trac.sagemath.org}. For smaller datasets, we might use other distributed Git repositories and store a central clone on platforms such as github. All the present data is public, and there is no concern about
unauthorised access. Through cloud hosting and local clones of
repositories, there are backups and redundancy.
\label{Sagesec}
\item[Dissemination] The \Sage codebase is publicly accessible through
  the trac server \href{http://trac.sagemath.org/}{trac.sagemath.org}
  and distributed within the \Sage software. For other data, we have an open access and open source policy and will advertise the data sets accordingly.
\label{Sagediss}
\item[Preservation and future access] By using the distributed system git to manage most of our data, we assure a local copy of the data within each participant machine. We rely on external platforms (Trac and Github) for public access. If it should happen that those platforms are not available any more, the data can easily be moved away to another platform.
\item[Partners involved] UPSud, CNRS, UGA, OXF, UVSQ
\label{Sagepres}


\begin{enumerate}
\item{Software code}
\begin{itemize}
\item\textit{Licence:} GPL
\item\textit{Nature of data:} Code
\item\textit{Reuse of existing data:} The data is added to the already large existing \Sage codebase.
\item\textit{Mean of production:} Code implementation by OpenDreamKit participants.
\item\textit{Data standard:} The code is mostly written in Python and Cython, also using the Rest syntax for documentation and \Sage coding conventions.
\item\textit{Usage for further experiments:} The code is merged in the software and can be distributed and reused through the Software. Through the git history,
one can trace back older versions of the code and re-enable a former state of the software.
\item\textit{Link:} \href{http://trac.sagemath.org/}{trac.sagemath.org}

\end{itemize}


\item{Database of strongly regular graphs}
\begin{itemize}
\item\textit{Licence:}  GPL
\item\textit{Nature of data:} A mix of data generators implemented in Python and
data stored as json objects. A description can be found in \href{http://arxiv.org/abs/1601.00181}{http://arxiv.org/abs/1601.00181}.
\item\textit{Reuse of existing data:} A part of this data was created,
  independently of OpenDreamKit, by a number of \Sage contributors.
D.~Pasechnik acknowledges OpenDreamKit support for his work on this topic.
\item\textit{Means of production:} Computers, mostly using \Sage and \GAP, and some purpose-written
Python code.
\item\textit{Usage for further experiments:} All the data  in this item is available from \Sage.
\item\textit{Link:} \url{http://doc.sagemath.org/html/en/reference/graphs/sage/graphs/strongly_regular_db.html}
\end{itemize}


\item{Database of special Hadamard matrices}
\begin{itemize}
\item\textit{Licence:} GPL
\item\textit{Nature of data:} A mix of data generators implemented in Python and hardcoded as text data.
\item\textit{Reuse of existing data:} A part of this data was created, independently of OpenDreamKit, by
a number of \Sage contributors.
D.~Pasechnik acknowledges OpenDreamKit support for his work on this topic.
\item{Means of production:} Computers, mostly using \Sage and \GAP, and some purpose-written
Python code.
\item\textit{Usage for further experiments:} All the data  in this item is available from \Sage.
\item\textit{Link:} \url{http://doc.sagemath.org/html/en/reference/combinat/sage/combinat/matrices/hadamard_matrix.html}
\end{itemize}
\end{enumerate}
\end{description}



\subsection{Additions to \GAP codebase}


\begin{description}
\item[Data storage and security] All addition to the the \GAP codebase will be stored within the distributed \GAP repository on github or a related repository. All the present data is public, and there is no concern about unauthorised access. Through cloud hosting and local clones of repositories, there are backups and redundancy.\label{GAPsec}
\item[Dissemination] The \GAP codebase is publicly accessible through github and mostly distributed as part of \GAP. For other data, we have an open access and open source policy and will advertise the data sets accordingly.
\label{GAPdiss}

\item[Preservation and future access] By using the distributed system git to manage most of our data, we assure a local copy of the data within each participant machine. We rely on external platform for public access. If it should happen that those platforms are not available any more, the data can easily be moved away to another platform. Datasets which are no longer being actively worked on will also be archived in the University's  research data (USTAN) repository and on zenodo.\label{GAPpres}
\item[Partners involved] USTAN, OXF
\end{description}


\begin{itemize}


\item{Name of data:} Additions to the \GAP codebase
\item\textit{Nature of data:} Software code
\item\textit{Licence:} GPL
\item\textit{Reuse of existing data:} The data is added to the already large existing \GAP codebase.
\item\textit{Means of production:} Code implementation by USTAN and other participants, building on existing elements of \GAP, which have been implemented by many people.
\item\textit{Data standard:} Follows the conventions of \GAP.
\item\textit{Usage for further experiments:} The code is merged in the software and can be distributed and reused through the Software. Through the git history,ne can trace back older versions of the code and re-enable a former state of the software.
\item\textit{Link:} \href{http://www.gap-system.org}{http://www.gap-system.org}
\end{itemize}



\subsection{Additions to \PariGP}

\begin{description}
\item[Data storage and security] All additions to the \PariGP software are stored on their server which is hosted at the University of Bordeaux, France.
\item[Dissemination] The \PariGP code, documentation and various binaries are publicly available on the server \href{http://pari.math.u-bordeaux.fr/}{pari.math.u-bordeaux.fr}. These are also packaged for major linux distributions.
\item[Preservation and future access] The \PariGP software has existed
  since 1979 and its website since 2003. It gets supports from various
  French and European institutions and has been hosted at the University of Bordeaux since its creation.
\item[Partners involved] CNRS
\end{description}


\subsection{Additions to MathHub portal}


\begin{description}
\item[Data storage and security] MathHub data is stored, versioned, and protected by the
state-of-the art GIT system.
\item[Dissemination] All data is to be ingested into the MMT system developed by Jacobs University. It is the main topic of WP6 to design a sustainable, flexible and distributed system that will allow for such efforts.
\item[Preservation and future access] All data will be hosted publicly on the MathHub portal (\url{http://mathhub.info}), a
dedicated information portal for active documents and data (flexiformal knowledge with
integrated semantic services). We can also expect that all the data produced will be protected under GIT as well, and hosted on GitHub or similar services. 
\item[Partners involved] JacobsUni, UZH, FAU
\end{description}

\begin{itemize}
\item{Name of data:}
\item\textit{Nature of data:}
\item\textit{Licence:} Original data will be licensed under an open knowledge license (see \url{http://opendefinition.org}), transformed data will be licensed as open as the original license allows it.
\item\textit{Reuse of existing data and Means of production:} Most data will be generated by transforming and semantic preloading of existing data sources (the mathematical data bases from WP6.)
\item\textit{Data standard:} The data created will be in the form of OMDoc/MMT flexiformalizations (representations of mathematical knowledge and data at flexible levels of formality). Since this data will aim to provide specifications for software, flexiformalisations for mathematical knowledge, and specifications for the implementation of mathematical knowledge into mathematical software, this process might require many different formats.
\item\textit{Usage for further experiments:} In order to enable computer algebra software systems such as \Sage and \GAP to benefit from this system, some of the data might be packaged as part of those distributions (through snapshotting of the federation of Git repositories hosting data).
\item\textit{Link:} \href{http://www.gap-system.org}{http://www.gap-system.org}
\end{itemize}


\subsection{Additions to nbdime}

Nbdime is a new subproject of Jupyter for diff and merge of Jupyter notebooks.
\begin{description}

\item[Data storage and security] All source code is stored in public repositories on \url{www.github.com} using the distributed version control system git. This means full copies of all files including their edit history are located on both external cloud infrastructure with professional backup routines and the personal computers of developers, and in the event of failure of either system restoring is trivial.
\item[Dissemination] Data can be accessed through the public Github repositories, providing open access. All source code is published under the standard open source licence for source code related to the Jupyter project, namely the ``Modified BSD License''.
\item[Preservation and future access] All data from Simula is published through public repositories under an open source licence, and copyright is assigned to the Jupyter project. This ensures the results can be kept alive and developed further alongside the Jupyter project. The Jupyter project has multiple international partners, both inside and outside Europe, both academic and commercial, ensuring continuation far beyond the end of OpenDreamKit.
\item[Partners involved] Simula

\end{description}

\begin{itemize}
\item\textit{Name of data:} nbdime project
\item\textit{Nature of data:} Software code
\item\textit{Licence:} Modified BSD Licence
\item\textit{Reuse of existing data:} The data reuses conventions from the existing Jupyter codebase, and reuses external open source software libraries where applicable.
\item\textit{Means of production:} Code implementation by SRL participants.
\item\textit{Data standard:} The code is written in Python and Javascript, using Jupyter coding conventions.
\item\textit{Usage for further experiments:} When completed, researchers and developers can use this tool to merge Jupyter notebooks when working with git repositories, an important improvement to a reproducible scientific workflow.
\item\textit{Link:} \href{https://github.com/martinal/nbdime}{https://github.com/martinal/nbdime}
\end{itemize}


\subsection{Additions to the LMFDB database}

The LMFDB database is currently hosted at UWarwick.  As well as the LMFDB database itself, the different components of the data are created and stored in a variety of places, and we only list here those for which ODK researchers are responsible.

\begin{enumerate}

\item{The LMFDB database}
\begin{description}
\item[Name of data] The LMFDB database
\item[Licence]  Under discussion by the LMFDB developers.
\item[Nature of data] A mongo database.  For a detailed description of its contents, see \url{https://github.com/LMFDB/lmfdb-inventory}. The website \url{http://www.lmfdb.org/} provides a user interface to the database and documents its contents, including its origin, extent and reliability.
\item[Reuse of existing data] Some of the data in LMFDB existed for many years, for example the Cremona Elliptic Curve Database (see {\tt ecdata} below), while others have been computed specifically for the project.   Contributors to LMFDB are listed at \url{http://www.lmfdb.org/acknowledgment}.
\item[Means of production] Computers, mostly using special purpose custom-written software, which in itself constitutes a significant research output by the contributors.
\item[Data standard] Each section of the LMFDB has its data quality documented and accessible via the website.  For example, see  \url{http://www.lmfdb.org/EllipticCurve/Q/Source}.
\item [Usage for further experiments] All the LMFDB data is accessible through its website.  Future plans include provision of an API for accessing the data systematically.
\item [Link]  \url{http://www.lmfdb.org/}
\item[Partners involved] UWarwirck
\end{description}

\item{{\tt ecdata}}
\begin{description}
\item[Name of data] The Cremona Elliptic Curve Database
\item[Licence]  Under discussion.
\item[Nature of data] A collection of plain text files containing tables of elliptic curves defined over~Q, together with their arithmetic invariants, contained in a {\tt git} repository at  \url{https://github.com/JohnCremona/ecdata}.  For a detailed technical description of their content and format, see  \url{https://github.com/JohnCremona/ecdata/blob/master/doc/file-format.txt}. The website  \url{http://johncremona.github.io/ecdata/} provides a simple user interface to the database and documents its contents, including its origin, extent and reliability.
\item[Reuse of existing data] All this data was computed by John Cremona, with additional contributions from Andrew Sutherland and Jeremy Rouse.
\item[Means of production] Computers, mostly using special purpose custom-written software, which in itself constitutes a significant research output by the contributors.
\item[Data standard] Documented at \url{http://johncremona.github.io/ecdata/}.
\item [Usage for further experiments] All the data in {\tt ecdata} is made available through the following channels: as an optional package in \Sage (with a small subset as standard); as an optional package in \PariGP; as standard in Magma; and through the LMFDB.  All of these, allow all researchers free access to use the data for their own investigations.
\item [Link] \url{http://johncremona.github.io/ecdata/}
\end{description}

\item{{\tt ecnf-data}}
\begin{description}
\item[Name of data] Database of Elliptic Curve over number fields \item[Licence]  Under discussion.
\item[Nature of data] A collection of plain text files containing tables of elliptic curves defined over algebraic number fields other than~Q, together with their arithmetic invariants, contained in a {\tt git} repository at https://github.com/JohnCremona/ecnf-data. For a detailed technical description of their content and format,  see https://github.com/JohnCremona/ecnf-data/blob/master/ecnf-format.txt.
\item[Reuse of existing data] This data was computed, by John Cremona and several others.
\item[Means of production] Computers, mostly using special purpose custom-written software, which in itself constitutes a significant research output by the contributors.
\item[Data standard] Not yet documented.
\item [Usage for further experiments] All the data in {\tt ecnf-data} is made available through the LMFDB, allowing all researchers free access to use the data for their own investigations.
\item [Link] \url{http://johncremona.github.io/ecnf-data/}
\end{description}

\item{{\tt bianchi-data}}
\begin{description}
\item[Name of data] Database of Bianchi modular forms
\item[Licence]  Under discussion.
\item[Nature of data] A collection of plain text files containing tables of Bianchi modular newforms of degree~$1$ over imaginary quadratic fields of class number~$1$, contained in a {\tt git} repository at \url{https://github.com/JohnCremona/bianchi-data}.
\item[Reuse of existing data] This data was computed by John Cremona.
\item[Means of production] Computers, using special purpose custom-written software, which in itself constitutes a significant research output by the contributor.
\item[Data standard] Not yet documented.
\item [Usage for further experiments] All the data in {ttbianchi-data} will be made available through the LMFDB, allowing all researchers free access to use the data for their own investigations.
\item [Link] \url{http://johncremona.github.io/ bianchi-data/}
\end{description}



\subsection{Data of experimental results published in scientific publications}

\begin{description}
\item[Data storage and security] All addition to the software codebases will be stored within the distributed repository of each software (the github central clone). For smaller datasets, including results of experiments, and publication sources, other distributed git repositories will be used and a central clone on platforms such as github will be stored. All the present data is public, and there is no concern about unauthorised access. Through cloud hosting and local clones of repositories, there are backups and redundancy.
\item[Dissemination] For other data,there is an open access and open source policy which will advertise the data sets accordingly.
\item[Preservation and future access] By using the distributed system git to manage most of the data, a local copy of the data within each participant machine is assured. External platforms (trac and github) for public access are relied on. If it should happen that those platforms are not available any more, the data can easily be moved away to another platform.
\item[Partners involved] UGA
\end{description}

\begin{itemize}
\item\textit{Name of data:} Experimental results of parallel computation benchmarks,
\item\textit{Nature of data:} any data related to an experiment, including timings,
  memory usage, input data, scripts used to run the experiments and description
  of the software stack used for their production
\item\textit{Licence:} Creative commons BY-ND for experiments' data, GPL for scripts
\item\textit{Reuse of existing data:} The data is open for reuse without modification.
\item\textit{Mean of production:} Experiments run by UGA participants.
\item\textit{Data standard:} Not yet documented
\item\textit{Usage for further experiments:} All information provided should adhere to
  the standards of reproducible research, in order to allow reproduction of
  this data.
\item\textit{Link:} None yet
\end{itemize}



\subsection{Additions to \Linbox}

\begin{description}
\item[Data storage and security] All addition to the software codebases will be stored within the distributed repository of each software (the github central clone). For smaller datasets, including results of experiments, and publication sources, other distributed git repositories will be used and a central clone on platforms such as github will be stored. All the present data is public, and there is no concern about unauthorised access. Through cloud hosting and local clones of repositories, there are backups and redundancy.
\item[Dissemination] For other data,there is an open access and open source policy which will advertise the data sets accordingly.
\item[Preservation and future access] By using the distributed system git to manage most of the data, a local copy of the data within each participant machine is assured. External platforms (trac and github) for public access are relied on. If it should happen that those platforms are not available any more, the data can easily be moved away to another platform.
\item[Partners involved] UGA
\end{description}

\begin{itemize}
\item\textit{Name of data:} Additions to the codebase of the \texttt{LinBox} software
\item\textit{Nature of data:} Software code
\item\textit{Licence:} LGPL
\item\textit{Reuse of existing data:} The data is added to the already large existing codebase.
\item\textit{Mean of production:} Code implementation by GA participants.
\item\textit{Data standard:} The code is mostly written in C++, also using the Doxygen syntax for documentation.
\item\textit{Usage for further experiments:} The code is merged in the software and can be distributed and reused through the Software. Through the git history,
one can trace back older versions of the code and re-enable a former state of the software.
\item\textit{Link:} \href{https://github.com/linbox-team}{github.com/linbox-team}
\end{itemize}



\subsection{Additions to Givaro}

\begin{description}
\item[Data storage and security] All addition to the software codebases will be stored within the distributed repository of each software (the github central clone). For smaller datasets, including results of experiments, and publication sources, other distributed git repositories will be used and a central clone on platforms such as github will be stored. All the present data is public, and there is no concern about unauthorised access. Through cloud hosting and local clones of repositories, there are backups and redundancy.
\item[Dissemination] For other data,there is an open access and open source policy which will advertise the data sets accordingly.
\item[Preservation and future access] By using the distributed system git to manage most of the data, a local copy of the data within each participant machine is assured. External platforms (trac and github) for public access are relied on. If it should happen that those platforms are not available any more, the data can easily be moved away to another platform.
\item[Partners involved] UGA
\end{description}


\begin{itemize}
\item\textit{Name of data:} Additions to the codebase of the \texttt{Givaro} software
\item\textit{Nature of data:} Software code
\item\textit{Licence:} LGPL
\item\textit{Reuse of existing data:} The data is added to the already large existing codebase.
\item\textit{Mean of production:} Code implementation by UGA participants.
\item\textit{Data standard:} The code is mostly written in C++, also using the Doxygen syntax for documentation.
\item\textit{Usage for further experiments:} The code is merged in the software and can be distributed and reused through the Software. Through the git history,
one can trace back older versions of the code and re-enable a former state of the software.
\item\textit{Link:} \href{https://github.com/linbox-team}{github.com/linbox-team}
\end{itemize}



\subsection{Additions to FFLAS-FFPACK}

\begin{description}
\item[Data storage and security] All addition to the software codebases will be stored within the distributed repository of each software (the github central clone). For smaller datasets, including results of experiments, and publication sources, other distributed git repositories will be used and a central clone on platforms such as github will be stored. All the present data is public, and there is no concern about unauthorised access. Through cloud hosting and local clones of repositories, there are backups and redundancy.
\item[Dissemination] For other data,there is an open access and open source policy which will advertise the data sets accordingly.
\item[Preservation and future access] By using the distributed system git to manage most of the data, a local copy of the data within each participant machine is assured. External platforms (trac and github) for public access are relied on. If it should happen that those platforms are not available any more, the data can easily be moved away to another platform.
\item[Partners involved] UGA
\end{description}

\begin{description}
\item[Data storage and security] All addition to the software codebases will be stored within the distributed repository of each software (the github central clone). For smaller datasets, including results of experiments, and publication sources, other distributed git repositories will be used and a central clone on platforms such as github will be stored. All the present data is public, and there is no concern about unauthorised access. Through cloud hosting and local clones of repositories, there are backups and redundancy.
\item[Dissemination] For other data,there is an open access and open source policy which will advertise the data sets accordingly.
\item[Preservation and future access] By using the distributed system git to manage most of the data, a local copy of the data within each participant machine is assured. External platforms (trac and github) for public access are relied on. If it should happen that those platforms are not available any more, the data can easily be moved away to another platform.
\item[Partners involved] UGA
\end{description}
\end{enumerate}



\section{Openaccess and Opendata policy}
\subsection{Publications}


Partners will be following the process explained below. The lead partner of the publication takes responsibility for the open access process for peer-reviewed publications.
\begin{enumerate}
\item{Publication in the journal of their choice:} Partners must be keeping in mind that the Agency asks projects not to accept more than 6 month embargo (to check the publishers’ policies, use \href{http://www.sherpa.ac.uk/romeo/}{http://www.sherpa.ac.uk/romeo/}
\item{Give open access to all peer-reviewed publications:} Maximum of 6 months embargo
\begin{itemize}
\item{Partners upload publications on http://arxiv.org/, or on another open access platform of their choice}
\item{Warn the Coordinator so that they keep list of OpenDreamKit publications updated on the project website}
\end{itemize}
\end{enumerate}


\subsection{Data related to open access publications}


The lead partner of a publication will send to the Project Manager all the data related to the peer-reviewed publication once it is given full open access. Data related to a publication are all the data needed to reexamine the research leading to the publication.
The Project Manager will publish the data linked to publications on \href{http://zenodo.org/}{http://zenodo.org/}. Thanks to the publications’ DOIs, the data will be linked to publications.



\subsection{Openaire}


Once publications are published on an open access platform and their data published on Zenodo, the OpenAire website will do the linkage between them. All OpenDreamKit published work will be present on the OpenDreamKit page available on \href{https://www.openaire.eu/}{https://www.openaire.eu/}.
In order for publications and data to appear on this website, one must state when completing forms on open access platform for publications and Zenodo websites that the concerned work is being financed by Horizon 2020 project number 676541.



\subsection{Other data in Open Access}


As far as it can be foreseen, all data produced and managed within the
frame of the OpenDreamKit project will be available in Open Access. The
project management itself occurs publicly on the project github
repository \url{https://github.com/OpenDreamKit/OpenDreamKit}. Most of
the work is moreover targeted at improving Open Source software.

\subsection{Data storage, access, and security}

\begin{enumerate}
\item\textbf{OpenData access}

Data produced within theOpenDreamKit frame must be accessible up to four years after the beginning of the project. Therefore partners must ensure access to their open access results.
The latter will all be available on EU funded platforms (Zenodo and Openaire) built and managed specifically to allow European research to give long-term open access to their results. The OpenDreamKit consortium therefore expresses its faith in the long-term availability of their work, considering the quality of the concerned platforms. Furthermore the data produced within the project will stay accessible on the opensource software platforms and on their repositories (github etc.).


\item\textbf{Data management policy per partner (when relevant)}
\begin{itemize}



\item{UPSud}

Most of the data created by UPSud is related to the software \Sage and
is progressively incorporated into the \Sage codebase. There might also be smaller data sets of tutorials, documentation and teaching content independent of the \Sage codebase which will be stored accordingly to the size and needs.



\item{USTAN}

Most of the data created by UStan is related to the software \GAP and will be incorporated into the \GAP codebase. There might also be smaller data sets of tutorials, documentation and teaching content independent of the \GAP codebase which will be stored accordingly to the size and needs.



\item{Simula}

All data sets produced by the work at SRL so far is in the form of source code and associated documentation and example files. The size of the produced data is small, on the order of tens of MB.



\item{USFD}



The outputs of the University of Sheffield will be mainly in the form of code. Where other data is needed it will be as a prerequisite for running a particular demonstration. 
\begin{description}
\item\textit{Data storage and security}: The code will be made available by github, or other suitable software version control and management systems, under BSD licenses. The code is public so there are no concerns about unauthorised access. For backups we will be relying on the distributed nature of git storage and back up facilities managed by the repository.

\item\textit{Dissemination}: Code will be available for dissemination by public accessibility and through the Open Data Science website (http://opendsi.cc) which is also github hosted.

\item\textit{Preservation and future access}: The git model ensures we will have local back ups of repositories across multiple machines, but the main data provision moving forward will be github. The University of Sheffield also has deals with figshare for making data available. We will exploit this mechanism of sharing as appropriate.
\end{description}



\item{Southampton}



There are no significant data sets associated with the work at Southampton. The most important data is resulting code and associated documentation and tutorials. The details below refer to this data set, and we expect the data set to be fairly small (order of 1 GB).
\begin{description}
\item\textit{Data storage and security}: The code is stored in a distributed repository (git at the moment), and a central clone of this repository is stored with Github.com in the cloud. We may use multiple repositories, and store a central copy of each on Github.com.


\item\textit{Security}: All the code is public, and there no concern about unauthorised access. Through cloud hosting and local clones of repositories, there are backups and redundancy.


\item\textit{Dissemination}: Data can be accessed through the public repositories, and the public website (probably this URL: \href{http://joommf.github.io}{http://joommf.github.io}, tbc), providing open access.


\item\textit{Preservation and future access}: They rely on provision of the data through \href{github.com}{github.com} but maintain local copies of the repository in case github.com ceases to exist or suffers from catastrophic technology failure. It is likely that other online repository hosting providers would be able to fill the gap (bitbucket.org is an existing alternative). The University of Southampton offers long term storage of small data sets for 10 years -- the repositories would fall into this categories. While the data wouldn't be conveniently accessible, this provides an extra layer of backups, from which accessible repositories and websites could be created easily.
\end{description}
\item{UVSQ}

Most of the data created by UVSQ is related to the software \Sage and will be incorporated into the \Sage codebase. There might also be smaller data sets of tutorials, documentation and teaching content independent of the \Sage codebase which will be stored accordingly to the size and needs.
\end{itemize}
\end{enumerate}

\subsection{Long term data preservation}

As seen earlier, most of the data (datasets, code, documentation,
website content, etc) produced within \ODK is version controlled and
available from public GitHub repositories. It is therefore accessible
to anyone on the web and, by the distributed nature of git, backed-up
in many places. GitHub's weight in today's IT landscape -- well
illustrated by its takeover by Microsoft -- gives an additional
insurance against its disappearance; it has become “too big to fail”
any time soon.

Nevertheless a serious back-up solution is necessary to guarantee the
long term preservation of our data. An effortless solution was found
with the new universal archive for software code called
\href{https://www.softwareheritage.org/}{www.softwareheritage.org/}.

Software Heritage is originally a French initiative from the INRIA
(National Institute for Research in Computing Science) which is now
sponsored by companies such as Microsoft, intel, Société Générale,
Google, GitHub or DANS. The goal of the archive is to "collect,
preserve, and make accessible source code for the benefits of present
and future generations." Software is to be taken in a broad sense, and
encompasses all kinds information mentioned earlier.

Though the archive is still at its beginning, it already includes all the public repositories from GitHub, which means that all the software components from OpenDreamKit are preserved. Each software component is assigned a unique identifier that is intrinsically bound to it. It does not rely on third parties, so it is truly persistent.

We have checked on a case-by-case basis that the software components
not hosted on GitHub are still covered by Software Heritage, e.g.
through other channels like Debian Source Package archives.

% In addition to the Software Heritage initiative which is growing more and more, one can see 

\section{Definitions}

\begin{itemize}
\item{Data:} a set of factual information saved on a medium, produced and collected according to various processes in the research process.
\end{itemize}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

