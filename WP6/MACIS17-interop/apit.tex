In our case study, we want to show integration of the \GAP, \Singular, and \Sage systems
in the MitM paradigm, so we need to generate API CDs for all of them and equip them with
OpenMath phrasebooks. The three systems are sufficiently different that we can consider
the development presented in this section a meaningful case study in the methodology and
investment of exposing the APIs of real-world systems in the form of \OMMT content
dictionaries.

In \cite{DehKohKon:iop16} we report on our work toward upgrading
\Sage's native interface to \GAP from the \emph{handle} paradigm to
\emph{semantic handles} paradigm. In the the \emph{handle} paradigm:
when a system $A$ delegates a calculation to a system $B$, the result
$r$ of the calculation is not converted to a native $A$ object (unless
it's of some basic type);
instead $B$ just returns a \emph{handle} $h$ (or reference) to the
object $r$. Later, $A$ can run further calculations with $r$ by
passing it as argument to functions or methods implemented by $B$. The
next desirable feature is for the handle $h$ to behave in $A$ as if it
was a native $A$ object; in other words, one wants to adapt the API
satisfied by $r$ in $B$ to match the API for the same kind of objects
in $A$. For example, the method call \texttt{h.cardinality()} on a
\Sage handle \texttt{h} to a \GAP object \texttt{G} should trigger in
\GAP the corresponding function call \texttt{Size(G)}. This is the
\emph{semantic handle} paradigm.

We further describe the implementation of this paradigm which builds
on the classical \emph{adapter pattern}. For conciseness, the adapters
are generated automatically from \emph{alignments} between the methods
from Sage's \emph{categories} (Sage's hierarchy of abstract classes
for the usual algebraic structures: sets, groups, algebras, ...) and
their GAP counterparts. In a first stage, the alignments are expressed
using annotations in the Sage categories. The second stage is to
exploit MitM to manage the alignments in order to properly scale from
custom one-to-one interfaces to interfaces between multiple systems.

The \emph{semantic handles} approach avoids the overhead of back and
forth conversions between $A$ and $B$ and enables the manipulation
from $A$ of objects of $B$, even if they have no native representation
in $A$.

However there are situations, like in Jane's scenario, where we
actually need to convert objects $r$ between $A$ and $B$. This
introduces the following additional challenges:
\begin{enumerate}
\item Both $A$ and $B$ need to have a native representation for $r$.
\item $A$ and $B$ need to support the (de)serialization of $r$.
\item The serialization format need to have a native representation
  for $r$
\item Alignments must be specified not only for the abstract methods
  but also for constructors
\item These alignments must be used at some point of the conversion.
\end{enumerate}

We can now refine our approach from Section~\ref{sec:mitm}. Recall
that $A$ and $B$ define each a system-near dialect of OpenMath, and
provide to MitM an API content dictionary describing that dialect. In
addition, MitM maintains a curated common ontology and a database of
alignments between the system-near dialects and that ontology. Then,
for a conversion of $r$ from $B$ to $A$,
\begin{enumerate}
\item $B$ serializes $r$ in $B$'s dialect of OpenMath
\item MitM exploits the alignments to translate this serialization
  into $A's$ dialect of OpenMath
\item $A$ deserializes it.
\end{enumerate}

In this section, we report on the ongoing work in the various systems
to export the desired API content dictionaries and support
(de)serialization.

\subsection{\Sage API Content Dictionaries}

\subsubsection{Extraction of \Sage API Content Dictionaries}

In \cite{DehKohKon:iop16} we describe the extraction of some of Sage's
API from its \emph{categories}. This exploited the mathematical
knowledge explicitly embedded in the code to cover a fairly large area
of mathematics (hundreds of kinds of algebraic structures such as
groups, algebras, fields, ...), with little additional efforts or need
to curate the output.

This extraction did not cover the \emph{constructors} which are needed
for (de)serialization, nor other areas of mathematics (graph theory,
elliptic curves, ...) where Sage developers did not opt to use
categories because the involved hierarchies of abstract classes are
very shallow and easily maintained by hand.

To go beyond, we took the following approach:
\begin{enumerate}
\item Construct a list of typical Sage objects.
\item Use introspection to analyze those objects, crawling recursively
  through their hierarchy of classes to extract constructors,
  available methods together with some mathematical knowledge.
\end{enumerate}

At this stage, the list of objects was crafted by hand to cover Jane's
scenarios and some others. In a later step we plan to take advantage
of one of Sage's coding standards: every concrete type must be
instantiated at least once in Sage's tests, and the instance be passed
trough a generic test suite that runs sanity checks for its advertised
properties (e.g. associativity, ...). Therefore, by a simple
instrumentation of Sage's test framework, we could run our exporter on
a fairly complete collection of Sage objects.

The process remains brittle and the export will require much curation:
\begin{itemize}
\item The signature of methods is incomplete: it specifies only the
  number and name of the arguments, and the type of the first
  argument.
\item For constructors, the type of all the arguments is known, but
  only for the specific call that led to the construction of the
  introspected object.
\item There is no distinction between mathematically relevant methods
  and purely technical ones like data structure manipulation helpers.
\item The export is very large and seems of limited use without
  alignments with the MitM ontology. At this stage we don't foresee
  much opportunities to produce such alignments other than manually.
\end{itemize}

Here are some potential directions to refine the signatures:
\begin{itemize}
\item Sage is being ported from Python 2 to Python 3 (tentative
  horizon: 2020). The latter enables \emph{gradual typing} in the form
  of type annotations in the method parameters and output. Assuming
  that the Sage developers community perceives the added value and
  adopts this programming style, and with some work to setup
  mathematically relevant types, we can hope for the Sage library to
  be progressively annotated with mathematically rich semantic. We
  will be pushing in this direction.
\item Some amount of type inference, either at the Sage or MitM levels.
\end{itemize}

\subsubsection{Serialization and deserialization}

\Sage being based on \Python benefits from its native serialization
support. For example, the dihedral group $D_4$ is serialized as a
binary string which encodes the following straight line program to be
executed upon deserialization:
\begin{lstlisting}
  pg_unreduce = unpickle_global('sage.structure.unique_representation', 'unreduce')
  pg_DihedralGroup = unpickle_global('sage.groups.perm_gps.permgroup_named', 'DihedralGroup')
  pg_make_integer = unpickle_global('sage.rings.integer', 'make_integer')

  pg_unreduce(pg_DihedralGroup, (pg_make_integer('4'),), {})
\end{lstlisting}
The first three lines recover the constructors for integers and for
dihedral groups from Sage's library. The last line applies them to
construct successively the integer $4$ and $D_4$.

Up to syntax, this serialization is close to the desired Sage's
OpenMath dialect\ednote{Add the translation of the above in OpenMath}.
We are therefore planning to extend Python's native (de)serializer to
use OpenMath as alternative serialization format, using Python's
OpenMath library library~\cite{py-openmath:on}. To support this, MMT
is being extended to support the classical idiom
\lstinline{let x=... let y = ... in ...}
of functional programming.

Here is some motivation for this approach:
\begin{itemize}
\item Python's serialization natively implements a certain number of
  natural optimizations, like factorization of identical subexpressions.
  % For example, a list of integers modulo 2 will be serialized as a
  % program like:

  %       Z2 = IntegerModRing(2)
  %       [Z2(0), Z2(1), Z2(0), Z2(0)]

  % Instead of recreating Z2 five times. In fact, it's even smarter in
  % this case, building Z2(0) and Z2(1) only once.
\item This decouples nicely the problem into two independent tasks:
  \begin{enumerate}
  \item Instrument the serialization to generate OpenMath as
    alternative format.
  \item Improve the serialization of \Sage objects to serialize
    \emph{by construction} rather than \emph{by data structure} to
    hide implementation details and make for straightforward
    alignments.
  \end{enumerate}

\item Good serialization support is a long time community goal for
  \Sage, in order to enable communication between parallel processes,
  build databases, etc. In addition serialization by construction is
  already valued as superior, being usually more concise and more
  resistant to changes across versions of \Sage. Therefore we can hope
  for long term progress there even if 2. is a large task and there is
  little man power specifically dedicated to OpenMath support.

  % There are generic tests; it is an official part of the review
  % process, etc. All in all Sage is doing relatively well (most objects
  % can be serialized and deserialized safely, often even so in a later
  % Sage version).

% - There is a pure Python implementation of the serializer. With some
%   luck (we still have to dig a bit more into the code), there is not
%   much to do to derive a subclass of the serializer that would output
%   OpenMath expressions instead of binary strings. Variant: derive from
%   the deserializer to obtain a converter from binary strings to
%   OpenMath.
\end{itemize}

% As in \GAP, a large part of the mathematical knowledge embedded in the
% \Sage library is encoded using its type system. This library is
% written in the \Python programming language which comes with a
% traditional object oriented dynamic type system.
% For example The MiTM ontology of Figure~\ref{fig:cgtontology}
% translates into a hierarchy of four abstract classes (\texttt{Group},
% \texttt{PermutationGroup}, \texttt{MatrixGroup},
% \texttt{FinitelyPresentedGroup}) and concrete classes
% (\texttt{SymmetricGroup}, \texttt{MathieuGroup},
% \texttt{LinearMatrixGroup}, ...).

% Altogether, the hierarchy of classes of \Sage contains thousands of
% abstract and concrete classes, with heavy use of multiple inheritance.
% To tame code bloat and make such a deep and large hierarchy
% maintainable, \Python's type system is enriched with a category system
% that collects closely related abstract classes (e.g. \texttt{Group},
% \texttt{GroupElement}, \texttt{GroupMorphism}, \texttt{GroupHomset}),
% together with explicitly represented mathematical knowledge, in a
% so-called \emph{category} (e.g that of \texttt{Groups}).
% See~\ref{Sage,Sage.Categories} for details.

% In \cite{DehKohKon:iop16} we describe the use of annotations in the code to enrich the
% mathematical knowledge in \Sage's categories with alignments with other systems, notably
% \MMT. This knowledge is then exported to generate interfaces theories. We also describe how
% this can be used to automatically generate \emph{handle interfaces} with other systems
% like e.g. \GAP.
% \begin{todolist}{NT@NT}
% \item next step: also export constructors to enable non-handle interfaces where objects
%   are actually exchanged. Besides, by nature certain areas of \Sage (e.g. graph theory,
%   elliptic curves, ...) have shallow hierarchy of classes; there categories become
%   irrelevant and are not used. \ednote{statistics would be useful here}
% \item using introspection to export the information; instrument TestSuite to export all
%   objects; parents and unique representation objects have a constructor method. pickling
%   by construction, ...
% \end{todolist}

\begin{newpart}{MK: I have completely reworked this and tried to tell a consistent story
    here. @MP: please re-read and correct.}
\subsection{\GAP API Content Dictionaries}

In \cite{DehKohKon:iop16} we describe our approach to export knowledge in the form of type
information from the \GAP system and produce a full \GAP API CD. This has been
improved considerably in the meantime. 

One of the measures is that since then the \emph{MitM foundation\ednote{MK@DM: introduce
    that in CGT above} was improved so that the primitives of \GAP's type system can be
  expressed in \OMMT natively}\footnote{It is subject to future investigation whether
  \MMT can serve as an external type-checker for \GAP.}: \GAP's type system is based on
sub-typing: \emph{Filters} express finer and finer subtypes of the universal
\emph{IsObject}. An object in \GAP can learn about its properties, meaning its type is
refined at runtime: A group can learn that it is Abelian or nilpotent and hence its type
changes.

The second measure was to \emph{upgrade the pre-existing \GAP phrasebook from the standard
  OpenMath CDs to the \GAP system dialect}. For this we needed to devise and implement a
special treatment of the \GAP constructors used to represent native \GAP objects. As \GAP
only had a weak notion of object construction, we achieve this by identifying functions
that create objects in the \GAP code base and then instrumenting them to store the
relevant arguments they were called with.  The instrumentation itself is minimal -- 57
lines of \GAP code, plus 100 lines for serializing and parsing \GAP objects as OpenMath
objects: this is all that was needed for the phrasebook.  The main -- and indeed
considerable -- challenge was to identify functions that construct objects, and which
arguments of those functions are then stored in the object.  In \GAP, objects are created
by calling the function \lstinline|Objectify| with a type and some data, hence we analyzed
all call-sites to this function and some light inference of the enclosing function. In the
\GAP library there are 665 calls to Objectify, and in the standard package distribution
there are an additional 1664.

Developing the instrumentation lead to many improvements of type-handling infrastructure
in \GAP itself, and the instrumentation will be integrated into a future version of \GAP,
making \GAP fully MitM capable\footnote{We expect to reap a considerable fringe benefit of
  the type information in the constructor annotations: static type analysis can be used to
  optimize the dynamic method dispatch and thus hopefully lead to efficiency gains in the
  system.}
With the constructor annotation in place it is possible to have \GAP represent
any object in a running session as either a primitive type (integers,
permutations, transformations, lists, floats, strings), using standard OpenMath
CDs, or a constructor applied to a list of arguments. This lends itself
perfectly to a representation in the \GAP API CD.
 
Finally, for the \GAP operations, we needed to develop a new regime for disambiguating
names between generic methods and their type instances\ednote{MK@MP: I think you can say a
  little bit more here. Else delete this sentence. MP@MK, I don't know what this
is about really,}

\ednote{MP: Put an example of OM\_Print here, maybe for a group, or for Cosets
  (as they are something that the standard OpenMath CDs in \GAP cannot do)}

\subsection{Standard OpenMath CDs as a \Singular API}

As we only need a very small part of \Singular for our case study, we were able to get by
with the OpenMath CDs for polynomials~\cite{OMCD:poly:on}. These are part of the standard
OpenMath CDs, a group of content dictionaries that describe (some) mathematical objects at
a high level of abstraction to be universally applicable. Building on the OpenMath
toolkits for OpenMath phrasebooks~\cite{py-openmath:on} and SCSCP
communication~\cite{py-scscp:on} in \Python -- which were developed for \Sage in the
OpenDreamKit project, we wrapped \Singular in a thin layer of python code that provides
\SCSCP communication. This work was undertaken by the sixth author as part of a summer
internship in about a week without prior expert knowledge of the system.
\end{newpart}
\ednote{MK@MK: say somewhere that expressing the CAS type systems natively in the MitM
  foundation puts all of the API CDs (and the MitM ontology) into a joint meaning space
  even though the system foundations are different. The interesting bit is that
  interoperability is at the ``Math level'' rather than at the ``system level''.}

\subsection{Alignments}

The initial alignments were produced manually, but from some of the initial alignments
and the \GAP API CDs we will be able to infer more alignments automatically.  For example,
the filter \texttt{GAP:IsGroup}\ednote{MK: introduce the namespaces above} is aligned with
\texttt{mitm:Group}, and the filter \texttt{GAP:IsPermGroup} is aligned with
\texttt{mitm:Subgroup SymmetricGroup [1..n]}.  \ednote{MP: Need to be more concrete here,
  in particular we should maybe describe how \GAP's notion of an action homomorphism
  translates through this?  Also is this even correct?}

We formalised the theory of symmetric groups of a set; in \GAP permutation groups
are represented as subgroups (with finite support) of the symmetric group of
$\mathbb{N}+$, and often one concretely has an isomorphism between the group one
is interested in and a subgroup of $S_{\mathbb{N}+}$, for example
via a group action.

\texttt{SylowSubgroup}s are more difficult: They are special groups in their
own right, namely groups whose size is a prime-power, but we also want them
to be identified with a certain subgroup of the group we are working
with.\ednote{MP: While I believe this to be an excellent additional example
  for \OMMT formalisation, this could be going too far for this paper}

\begin{newpart}{MK@DM+NT: please check this }
  Another source of alignments are the existing ad-hoc \Sage-to-$X$ translations. These
  are (mainly) given as \Sage code annotations that relate \Sage operations and
  constructors with those of system $X$. We can harvest\ednote{MK@NT: I think you already
    do that, if so, please document above, if not, please do!} those as alignments between
  the \Sage API CDs and $X$ API CDs. These can be combined with the \Sage-to-MitM
  alignments into $X$-to-MitM alignments. While $X$-to-$Y$ alignments are the application,
  $X$/$Y$-to-MitM alignments scale better, since they can be arbitrarily combined and make
  the induced knowledge management workflows star-shaped.
\end{newpart}
\ednote{MK@MK: still two write: the alignment-based priorization and suggestion mechanism. }


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:
