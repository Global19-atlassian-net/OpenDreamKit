\documentclass{beamer}

\usepackage[utf8]{inputenc}
\usepackage{tikz}\usetikzlibrary{trees}
\usepackage{commath}

\usepackage{booktabs}
\usepackage{listings}
\lstset{
  language=python,
  basicstyle=\scriptsize,
}
\usetheme{ODK}

\AtBeginSection[]
{
  \begin{frame}<beamer>
    \frametitle{Outline}
    \tableofcontents[currentsection]
  \end{frame}
}

\title[Workpackage 5]{Workpackage 5:\\ High Performance Mathematical Computing}

\author{ClÃ©ment Pernet}

\institute[ODK Project review]{First OpenDreamKit Project review}

\date{Brussels, \today}

\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Introduction}
\begin{frame}
  \frametitle{Goal: delivering high performance to maths users}

    \begin{center}
    \includegraphics[width=0.8\textwidth]{software_stack}
  \end{center}

    \pause
    \begin{itemize}
    \item Improve/Develop parallel computing features of dedicated software
      kernels
    \item Expose them through the software stack
    \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Introduction}
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Main tasks under review for the period}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Task 5.4: Singular}
\begin{frame}
  \frametitle{Task 5.4: Singular}
\begin{center}{\Large
    \textbf{Singular}: A computer algebra system for polynomial computations.}
\end{center}

  \begin{itemize}
  \item Already has a generic parallelization framework
  \item Focus on optimizing  kernel routines for fine grain parallelism
  \end{itemize}

  \begin{description}
  \item[D5.6:] Quadratic sieving for integer factorization
  \item[D5.7:] Parallelization of matrix fast Fourier Transform
  \end{description}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{D5.6: Quadratic Sieving for integer factorization}

  \begin{block}{Quadratic Sieving for integer factorization}
    \begin{description}
    \item[Problem:]  Factor an integer $n$ into prime factors
    \item[Role:] Crucial in algebraic number theory, arithmetic geometry.
    \item [Earlier status:] no HPC implementation for large instances:
      \begin{itemize}
      \item only fast code for up to 17 digits,
      \item only partial sequential implementation for large numbers
      \end{itemize}
    \end{description}
    \end{block}
\end{frame}

\begin{frame}
  \frametitle{D5.6: Quadratic Sieving for integer factorization}
    \begin{block}{Achievements}
      \begin{itemize}
      \item Completed and debugged implementation of large prime variant
      \item Parallelised sieving component of implementation using OpenMP
      \item Experimented with a parallel implementation of Block Wiedemann
      \end{itemize}
\end{block}
\begin{block}{Results}

      \begin{itemize}
      \item Now modern, robust, parallel code for numbers in
        17--90 digit range \pause
%      \item Block Wiedemann:  \textbf{SIMD} vs \textbf{thread level}
%        parallelism       \pause
%, $\leadsto$ no faster than existing code
      \item Significantly faster on small multicore machines
      \end{itemize}
\vspace{-1.5em}
      \begin{center}
        \begin{table}
          \caption{Speedup for four cores (c/f single core): }
        \begin{tabular}{c|ccccc}
        \toprule
            {Digits} & 50 & 60 & 70 & 80 & 90\\
            \midrule
                {Speedup} & $1.1\times$ & $1.76\times$ & $1.55\times$ & $2.69\times$ & $2.80\times$\\
                \bottomrule
      \end{tabular}
\end{table}
      \end{center}
    \end{block}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{D5.7: Parallelise and assembly optimize FFT}

  \begin{block}    {FFT: Fast Fourier Transform over $\mathbb{Z}/p\mathbb{Z}$}
    \begin{itemize}
    \item Among the top 10 most important algorithms
    \item Key to fast arithmetic (integers, polynomials)
    \item Difficult to optimize: high memory bandwidth requirement
    \end{itemize}
    \begin{description}
    \item[Earlier status:]\
      \begin{itemize}
      \item world leading \textbf{sequential} code in MPIR and FLINT;
      \item no parallel code.
        \end{itemize}
    \end{description}
  \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{D5.7: Parallelise and assembly optimize FFT}
  \begin{block} {Achievements}
  \begin{itemize}
\item Parallelised Matrix Fourier implementation using OpenMP
\item Assembly optimised butterfly operations in MPIR
\end{itemize}
  \end{block}

\begin{block}{Results:}

\begin{itemize}
\item $\approx 15\%$ speedup  on Intel Haswell
\item $\approx 20\%$ speedup on Intel Skylake
\item Significant speedups on multicore machines
\end{itemize}
\end{block}

\vspace{-1em}
\begin{table}
  \caption{Speedup of large integer multiplication on 4/8 cores:}
  \begin{tabular}{cccccccc}
  \toprule
{Digits} & 3M & 10M & 35M & 125M & 700M & 3.3B & 14B\\
\midrule
    {4 cores} & $1.35\times$ & $2.67\times$ & $2.92\times$ & $2.92\times$ & $3.01\times$ & $2.95\times$ & $3.32\times$ \\
{8 cores} & $1.35\times$ & $3.56\times$ & $4.22\times$ & $4.36\times$ & $4.50\times$ & $4.31\times$ & $5.49\times$\\
\bottomrule
\end{tabular}
\end{table}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Task 5.5: MPIR}
\begin{frame}
  \frametitle{Task 5.5: MPIR}
\begin{center}
  {\Large  \textbf{MPIR} : a library for big integer arithmetic}
\end{center}
\begin{itemize}
  \item Bignum operations: fundamental across all of computer algebra
  \end{itemize}

  \begin{block}
    {D5.5: Assembly superoptimization}
    \begin{itemize}
    \item MPIR contains assembly language routines for bignum operations
    \\ $\leadsto$ hand optimised for every new microprocessor architecture
    \\ $\leadsto \approx 3-6$ months of work for each architecture
    \item Superoptimisation: rearranges instructions to get optimal
      ordering
    \end{itemize}

    \begin{description}
      \item[Earlier status:]\
        \begin{itemize}
        \item No assembly code for recent ($> 2012$) Intel and AMD chips (Bulldozer,
          Haswell, Skylake, \dots)
        \end{itemize}
            \end{description}



    \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\frametitle{D5.5: Assembly superoptimisation}

\begin{block} {Achievements}
\begin{itemize}
\item A new assembly superoptimiser supporting recent instruction sets%, including AVX
\item Superoptimised handwritten assembly code for Haswell and Skylake
\item Hand picked faster assembly code for Bulldozer from existing implementations
\end{itemize}
\end{block}
\begin{block}
  {Results:}
\begin{itemize}
\item Sped up basic arithmetic operations for Bulldozer, Skylake and Haswell
\item Noticeable speedups for bignum arithmetic for all size ranges
\end{itemize}
\end{block}


%% \begin{table}
%% \caption{Speedups for bignum operations}
  \begin{tabular}{cccccccc}
  \toprule
{Op} & \mbox{Mul (s)} & \mbox{Mul (m)} & \mbox{Mul (b)} & \mbox{GCD (s)} & \mbox{GCD (m)} & \mbox{GCD (b)} \\
\midrule
{Haswell} & $1.18\times$ & $1.27\times$ & $1.29\times$ & $0.72\times$ & $1.45\times$ & $1.27\times$\\
{Skylake} & $1.15\times$ & $1.20\times$ & $1.22\times$ & $0.84\times$ & $1.65\times$ & $1.32\times$ \\
\bottomrule
\end{tabular}
%\end{table}

s $= 512$ bits, m $= 8192$ bits, big $= 100$K bits

\end{frame}
%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}[fragile]

%% \frametitle{D5.5: Assembly superoptimisation}


%% \begin{table}
%% \caption{Speedups for bignum operations}
%%   \begin{tabular}{cccccccc}
%%   \toprule
%% {Op} & \mbox{Mul (s)} & \mbox{Mul (m)} & \mbox{Mul (b)} & \mbox{GCD (s)} & \mbox{GCD (m)} & \mbox{GCD (b)} \\
%% \midrule
%% {Haswell} & $1.18\times$ & $1.27\times$ & $1.29\times$ & $0.72\times$ & $1.45\times$ & $1.27\times$\\
%% {Skylake} & $1.15\times$ & $1.20\times$ & $1.22\times$ & $0.84\times$ & $1.65\times$ & $1.32\times$ \\
%% \bottomrule
%% \end{tabular}
%% \end{table}

%% s $= 512$ bits, m $= 8192$ bits, big $= 100$K bits

%% No substantial speedups were found for the older, less sophisticated Bulldozer over existing assembly routines.

%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Task 5.6: Combinatorics}
\begin{frame}[fragile]
  \frametitle{Task 5.6: Combinatorics}
%\begin{frame}[fragile]{Today: Map/Reduce of RESets}

  \begin{center}
    {%
      \begin{minipage}{9cm}\Large\bf
        Perform a {\color{red}map/reduce} operation on a very large set
        described {\color{blue}recursively}.
      \end{minipage}
    }
  \end{center}
  \begin{block}{Large range of intensive applications in combinatorics:}
  \begin{itemize}
  \item Compute the cardinality, or more generally any kind of generating series
  \item Test a conjecture: i.e. find an element of $S$ satisfying a specific
    property %or check that all of them do
  \item Count/list the elements of $S$ having this property
  \end{itemize}
\end{block}

  \begin{block}{Specificity of combinatorics:}
  \begin{itemize}
  \item Typically the sets \emph{don't fit in the computers} memory / disks
    and are enumerated on the fly (example of value: $10^{17}$~bytes).
  \item Easy to parallelize, if the set is flat (a list, a file, stored on a disk).
    \bigskip
  \end{itemize}
\end{block}
\end{frame}



\begin{frame}[fragile]{A Challenge: The tree of numerical semigroups}
\newcommand{\sgnode}[1]{{\bf \left<#1\right>}}
\newcommand{\gr}[1]{{\color{gray} #1}}

Extremely unbalanced. Need for an \textbf{efficient load balancing algorithm}.
\[\tiny
\begin{tikzpicture}[baseline={([yshift=-5cm]current bounding box.north)},
  scale=0.7,
  level distance=1.5cm, 
  inner sep=2mm,
  level/.style={sibling distance=1.55cm}]
    \node {$\sgnode{1}$}
    child {node {$\sgnode{2,3}$}
      child [sibling distance=4.5cm] {node {$\sgnode{3,4,5}$}
        child {node {$\sgnode{4,5,6,7}$}
          child [sibling distance=2cm]{node {$\sgnode{5,6,7,8,9}$}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            edge from parent node [left] {4}}
          child [sibling distance=1.9cm]{node {$\sgnode{\gr 4,6,7,9}$}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            edge from parent node [left] {5}}
          child {node {$\sgnode{\gr 4,\gr 5,7}$}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            edge from parent node [right] {6}}
          child {node {$\sgnode{\gr 4,\gr 5,\gr 6}$}
            edge from parent node [right] {7}}
          edge from parent node [left] {3}
        }
        child{{} edge from parent[draw=none]}
        child{{} edge from parent[draw=none]}
        child {node {$\sgnode{\gr 3,5,7}$}
          child {node {$\sgnode{\gr 3,7,8}$}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            edge from parent node [left] {5}}
          child {node {$\sgnode{\gr 3,\gr 5}$} edge from parent node [right] {7}}
          edge from parent node [left] {4}
        }
        child {node {$\sgnode{\gr 3,\gr 4}$}
          edge from parent node [right] {5}
        }
        edge from parent node [left] {2}
      }
      child [sibling distance=4.5cm] {node {$\sgnode{\gr2,5}$}
        child {node {$\sgnode{\gr2,7}$}
          child {node {$\sgnode{\gr2,9}$}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            edge from parent node [right] {7}
          }
          edge from parent node [right] {5}
        }
        edge from parent node [right] {3}
      }
      edge from parent node [left] {1}
    }
   ;
  \end{tikzpicture}
\]
\pause

$  \leadsto$ need for a high level task parallelization framework. 
\end{frame}



%% \begin{frame}{Work-Stealing System Architecture}
%%   Work stealing algorithm (Leiserson-Blumofe / Cilk):

%% \[\hspace{-0.7cm}\includegraphics[width=12.5cm]{scheme.pdf}\]
%% \end{frame}

\begin{frame}{Work-Stealing System Architecture}
  
  \begin{block}{A Python implementation}
    \begin{itemize}
    \item Work stealing algorithm (Leiserson-Blumofe / Cilk)
    \item Easy to use, easy to call from sage
    \item Already, a dozen  use case
    \item Scale well with the number of CPU cores
    \item Reasonably efficient (knowing that this is Python code).
    \end{itemize}
  \end{block}

  \begin{block}{References}
\begin{itemize}  \item Trac Ticket $13580$ \url{http://trac.sagemath.org/ticket/13580}
    \bigskip
    
  \item \textit{Exploring the Tree of Numerical Semigroups} Jean Fromentin
    and Florent Hivert \url{https://hal.inria.fr/UNIV-ROUEN/hal-00823339v3}
\end{itemize}
  \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Task 5.7: Pythran}
\begin{frame}
  \frametitle{Task 5.7: Pythran}
  \begin{center}
    {\Large \textbf{Pythran}: a NumPy-centric Python to C compiler}
  \end{center}
  \begin{columns}
    \begin{column}
      {.48\textwidth }
          \includegraphics[width=\textwidth]{software_stack}
    \end{column}
    \begin{column}
      {.48\textwidth }
  \begin{itemize}
  \item Many High level VRE rely on the Python language
  \item High performance is most often achieved  by the C language\pause
  \item Python to C compilers: 
    \begin{description}
    \item[Cython:] general purpose
    \item[Pythran:] narrower scope, better at optimizing Numpy code (Linear algebra)
    \end{description}
  \end{itemize}
    \end{column}
  \end{columns}
\pause
  \begin{center}
    \textbf{Goal: Implement the convergence}

    \begin{description}
      \item[D5.4] Improve Pythran typing system
      \item[D5.2] Make Cython use Pythran backend to optimize Numpy code
    \end{description}
  \end{center}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{D5.2: Make Cython use Pythran backend for NumPy code}

  \begin{center}
    \includegraphics[width=.75\textwidth]{float_graph}\\
  \end{center}
  \begin{lstlisting}
import numpy
cimport numpy
def float_comp (numpy.ndarray[numpy.float_t, ndim=1] a,
                 numpy.ndarray[numpy.float_t, ndim=1] b):
     return numpy.sqrt(numpy.sqrt(a*a+b*b))
\end{lstlisting}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{D5.2: Make Cython use Pythran backend for NumPy code}

  \begin{center}
    \includegraphics[width=.65\textwidth]{harris_graph}
  \end{center}

  \begin{lstlisting}[basicstyle=\tiny]
def harris(numpy.ndarray[numpy.float_t, ndim=2] I):
  cdef int m = I.shape[0]
  cdef int n = I.shape[1]
  cdef numpy.ndarray[numpy.float_t,ndim=2] dx = (I[1:,:] - I[:m-1,:])[:,1:]
  cdef numpy.ndarray[numpy.float_t,ndim=2] dy = (I[:,1:] - I[:,:n-1])[1:,:]
  cdef numpy.ndarray[numpy.float_t, ndim=2] A = dx * dx
  cdef numpy.ndarray[numpy.float_t, ndim=2] B = dy * dy
  cdef numpy.ndarray[numpy.float_t, ndim=2] C = dx * dy
  cdef numpy.ndarray[numpy.float_t, ndim=2] tr = A + B
  cdef numpy.ndarray[numpy.float_t, ndim=2] det = A * B - C * C
  return det - tr * tr
\end{lstlisting}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%       \frametitle{D5.4: Improve Pythran typing system}
%% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Task 5.8: SunGridEngine in JupyterHub}
\begin{frame}
  \frametitle{Task 5.8: SunGridEngine integration in JupytherHub}
  \begin{block}{Access to big compute}
   \begin{itemize}
   \item Traditional access to supercomputers is difficult
   \item Notebooks are easy but run on laptops or desktops
   \item We need a way to connect notebooks to supercomputers
   \end{itemize}
  \end{block}
  \begin{block}{Sun Grid Engine}
    A job scheduler for Academic HPC Clusters
    \begin{itemize}
    \item Controls how resources are allocated to researchers
    \item One of the most popular schedulers
    \end{itemize}
  \end{block}

  \begin{block}{Achievements: D5.3}
  \begin{itemize}
  \item Developed software to run Jupyter notebooks on supercomputers
  \item Users don't need to know details. They just log in.
  \item Demonstration install at University of Sheffield
  \end{itemize}
  \end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Progress report on other tasks}
\begin{frame}
  \frametitle{Progress report on other tasks}

  \begin{block}{T5.1: Pari}
    \begin{itemize}
    \item Generic parallelization engine is now mature, released (D5.10, due M24)
    \end{itemize}
  \end{block}
  \begin{block}{T5.2: GAP}
    \begin{itemize}
    \item 6 releases were cut integrating contributions of D3.11 and D5.15
    \item Build system refactoring for integration of HPC GAP
    \end{itemize}
  \end{block}
  \begin{block}{T5.3: LinBox}
    \begin{itemize}
    \item Algorithmic advances (5  articles) on linear algebra and
      verified computing
    \item Software releases and integration into SageMath
    \end{itemize}
  \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \subsection{Task 5.1: Pari}
%% \begin{frame}
%%   \frametitle{Task 5.1: Pari}
%% \end{frame}
%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \subsection{Task 5.2: GAP}
%% \begin{frame}
%%   \frametitle{Task 5.1: GAP}
%% \end{frame}
%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \subsection{Task 5.3: LinBox}
%% \begin{frame}
%%   \frametitle{Task 5.3: LinBox}
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
