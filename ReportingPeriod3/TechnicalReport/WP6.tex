\subsubsection{WorkPackage 6:  Data/Knowledge/Software-Bases}\label{dksbases}
%Explain, task per task, the work carried out in WP during the reporting period giving details of the work carried out by each beneficiary involved.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Overview}

In a series of workshops (September 2015 in Paris, January 2016 in St. Andrews, June 2016 in Bremen, and July 2016 in Bia{\l}ystok, 2017 in Orsay, 2018 in Cernay, 2019 in Cernay), the participants working on \WPref{dksbases} met and discussed the topic of integrating the \pn systems into a mathematical VRE toolkit.
Additionally, Florian Rabe was employed at both FAU and UPSud throughout 2018 and 2019 to deepen the integration.

Key results of the first two reporting periods were
\begin{compactitem}[\bf R1.]
\item the observation that \emph{knowledge-aware interoperability of software and database-systems is the most critical objective} for \WPref{dksbases} in the \pn project.
\item the consensus that this can be achieved by \emph{aligning the mathematical knowledge underlying the various systems},
\item the existing integration of mathematical computation systems in the Sage and Jupyter systems must be complemented with a similar integration of mathematical databases.
\end{compactitem}
This requires explicitly representing the three aspects of math VREs -- Data (D), Knowledge (K), and Software (S) -- and basing computational services and inter-system communication on a joint \DKS-base.
These results are engrained in the ``Math-in-the-Middle'' (MitM) paradigm~\cite{DehKohKon:iop16}, which gives a representational basis for specification-based interoperability of mathematical software systems -- so that they can be integrated in a VRE toolkit.
In the MitM paradigm, the mathematical knowledge underlying the VREs (K) and the interface for each system (S) are represented as modular theory graphs in the OMDoc/MMT format.
For the data aspect (D) we have extended the concept of OMDoc/MMT theories to ``virtual theories'' that allow the practical management of possibly infinite theories, see~\cite{ODK-D6.5} for details.

Through the concerted effort of the WP6 participants, we have been able to implement this design and instantiate it with generate theory graphs for the \GAP and \Sage systems and integrating the \LMFDB (see~\cite{ODK-D6.5}.
Based on this, we were able to generically integrate \GAP, \Sage, and \LMFDB via the standardised SCSCP protocol~\cite{HorRoz:ossp09}. This case study shows the feasibility of the design. 

\begin{wrapfigure}r{6cm}\vspace*{-1em}
\input{../../WP6/D6.10/tetrapod-arms}\vspace*{.5em}
\caption{Five Aspects of Math VREs, a Tetrapod Structure}\label{fig:tetrapod}\vspace*{-1.5em}
\end{wrapfigure}
In the \textbf{third reporting period}, the focus was on the \textbf{representation and curation of mathematical data}, building on the earlier work. We have refined the original notion of \DKS-bases from the grant proposal into a tetrapodal structure which captures the four primary aspects of ``doing Maths'' that have to be supported in a VRE toolkit: narration (papers and textbooks), computation (algorithms and software), inference (theorems and proofs), and tabulation (database schemas and datasets).
These are joined via a fifth modular organization aspect -- see the introduction  of \cite{ODK-D6.10} and \cite{CarFarKohRab:bmobb19} for a discussion.

We have taken up the general discussion of research data, the FAIR principles, and have adapted them to the case of mathematical research data. The outcome of this was the observation that -- even though mathematics deals with ideal and abstract objects -- it is often possible to describe these objects concisely by representing them as database structures in a way that complements they their formal symbolic descriptions. The codecs from the ``virtual theories'' approach developed in \WPref{dksbases} tie these two representations together: they link the database level of mathematical data sets with the MitM ontology -- and from there via the interface theory graphs interface it to the mathematical software systems in \pn.

We undertook three larger case studies to bring this about:
\begin{itemize}
\item developing the system data.mathhub.info for managing mathematical data sets MitM-style and equipping it with a search UI; see the report on \taskref{dksbases}{data-LMFDB} below,
\item exporting a the Isabelle knowledge base (via a subcontract), and equipping it with a semantic search facility; see the report on \taskref{dksbases}{isabelle} below,
\item extending the formula search capabilities developed in the first reporting period to Jupyter notebooks; see the report on
 \taskref{dksbases}{mws} below.
\end{itemize}
This wraps up and integrates the work in \WPref{dksbases} combining aspects of Data (D) (now captured by tabulation), Knowledge (K) (now captured by organization and inference), and Software (S) (now captured by computation).
Importantly, the joint system addresses semantically the central aspects of all four FAIR requirements for the open sharing of research data. 
For a joint and integrated final report on this, see ~\cite{ODK-D6.10}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\paragraph{Milestones}

% month 36
\subparagraph{\longmilestoneref{dksbases-interop1}}
This milestone was addressed in the second reporting period.
\medskip
%\emph{“User story: thanks to a fully functional prototype integrating of at least the systems \GAP, \Sage, \Singular, and \LMFDB via the \SCSCP Protocol, end users shall be able to run calculations involving any combination of those systems from any of them.
%  This prototype will be the basis for integration work for additional systems and the user interface from WP4.”}
%\medskip
%
%Workpackage \textbf{WP6} is fully on track with this milestone.
%After first integration and DKS prototypes (the MitM VRE middleware  framework) became available in late fall 2017 (see~\cite{KohMuePfe:kbimss17,WieKohRab:vtuimkb17}) we were able to develop more sophisticated -- and mathematically more realistic/relevant -- use cases~\cite{CreLow:mdcmds18} and generalize those parts of the framework that had been overly specific to the first use cases.
%This involved non-trivial investments in all parts of the framework, as well as the system API theory generation systems and (in particular) the MitM ontology. 

% month 42
\subparagraph{\longmilestoneref{dksbases-interop2}}
\emph{“The goal of this milestone was to take into account all the operational experiences with the first prototype and add more systems and integrate some of the UI components from WP4.
  The experiences with the preparation of this prototype allow us to estimate the joining costs of adding a system to the OpenDreamKit VRE toolkit, which is an important measure of the flexibility of the Math-In-the-Middle approach.”}

The state of the MitM VRE middleware is sufficiently mature that most of the functionality can be configured by writing domain and system knowledge in form of OMDoc/MMT theories, but without requiring extensions of the system (e.g., changes to the programming of the VRE systems or the MMT mediator).
This means that additional computational systems can be added at the cost of generating system API theories, extending the MitM ontology, and supplying alignments.

In the \emph{third review period} we have concentrated on mathematical data sources.
Our analysis of systems in \taskref{dksbases}{data-OEIS}, \taskref{dksbases}{data-findstat}, and even more \taskref{dksbases}{data-LMFDB} has revealed that to achieve deep and meaningful FAIRness of mathematical research data -- in particular of interoperability (I) -- we have to semantically model the mathematical objects in math-aware representations (as described above).
As a consequence, we have to integrate mathematical data systematically into the \pn VRE toolkit, giving rise to the refined tetrapodal model described above. In particular, this integration must consider individual datasets rather than dataset-related systems like OEIS, FindStat, or LMFDB.
The \dmh system was expressly designed to do this: we can just specify a dataset in the MDDL language (see~\cite{BerKohRab:tumdi19,ODK-D6.10}) and then generate a database infrastructure including user interface and import facility from it, resulting in a MitM-Interoperable VRE component for that dataset.
We have tested and evaluated this setup on a special Math Data Workshop~\cite{ODK-WDM19} using five data sets supplied by one internal and two external mathematicians.
This showed that -- after a learning period of a day and with some help from \pn knowledge engineers, external users can MitM-integrate datasets by specifying their structure and semantics and supplying them in a specification-conforming format in under a day of work.
We anticipate that creating the alignments (see \cite{ODK-D6.5}) that relate the mathematical background of these datasets to algorithms in computational MitM systems like \GAP, \Sage, and \Singular is of the same order of magnitude. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\paragraph{Tasks}
\medskip

\subparagraph{\longtaskref{dksbases}{data-assessment}}
\label{dksbases@data-assessment}
This task was addressed in the first reporting period.
\medskip

\subparagraph{\longtaskref{dksbases}{data-triform}}
\label{dksbases@data-triform}
This task was addressed in the first reporting period.
%For this task we have specified and implemented the concept of virtual theories that can contain large -- theoretically even infinite -- numbers of declarations and objects (e.g. 3.5M declarations in the LMFDB data base for elliptic functions) in OMDoc/MMT.
%Virtual theories are characterized by the fact that they are too large to keep in main memory of the MMT System and have to be partially and lazily imported from an external data store.
%We have reported on the design in \longdelivref{dksbases}{design}, on a first implementation on the international conference (MACIS 2017)~\cite{WieKohRab:vtuimkb17}, and finally on an extended use-case in \LMFDB in \longdelivref{dksbases}{psfoundation}. 
\medskip

\subparagraph{\longtaskref{dksbases}{data-design}}
\label{dksbases@data-design}
This task was addressed in the first reporting period.
%This task was directly addressed in the \WPref{dksbases} workshops in the first year and has led to the design and implementation in \delivref{dksbases}{design}. A first implementation has been presented on the international conference (MACIS 2017)~\cite{WieKohRab:vtuimkb17}, and finally on an extended use-case in \LMFDB in \longdelivref{dksbases}{psfoundation}.
% \medskip

\subparagraph{\longtaskref{dksbases}{data-foundationCAS}}
\label{dksbases@data-foundationCAS}
This task was addressed in the first reporting period. 
%In the course of the deliberations in the \WPref{dksbases} workshops we saw a shift from the development of computational foundations and verification towards API/Interface function specifications to enable semantic system interoperability via the Math-in-the-Middle (MitM) Ontology.
%Consequently, emphasis has changed to the generation of system API theories for \GAP, \Sage, \Singular, and \LMFDB, which act as OpenMath content dictionaries.
%The computational foundations exist but are rather more simple than originally anticipated.
%Much of the functionality has been offloaded to the SCSCP standard -- remote procedure call with OpenMath representations of the mathematical objects -- developed in the SCIENCE Project.
%As a direct consequence of the work in \pn the OpenMath Society has promoted the \SCSCP protocol into as an OpenMath Standard.
%
%Conversely, the \GAP and \Sage CDs are rather more elaborated than anticipated in the proposal, and thus form a viable basis for alignment with the MitM Ontology.
%
%The MitM integration paradigm is the result of our research and development on the computer algebra foundations in this task has been presented on the international conference MACIS 2017~\cite{KohMuePfe:kbimss17} and is described in deliverable \longdelivref{dksbases}{psfoundation}, which presents an advanced CAS integration use case. 
%The MitM ontology and the system API theories have been developed to the point, where the data model is fully developed and the contents cover the use cases corresponding to this task and \longlocaltaskref{dksbases}{data-design} are surveyed in \longdelivref{dksbases}{lfmverif}.
\medskip

\subparagraph{\longtaskref{dksbases}{research-categories}}
\label{dksbases@data-research-categories}
This task was addressed in the second reporting period. In this period, the infrastructure has matured and been extended with a data component \dmh.

\subparagraph{\longtaskref{dksbases}{data-OEIS}}
\label{dksbases@data-OEIS}
This task was addressed in the first reporting period.
%For the OEIS case study we have parsed the OEIS data and converted it into OMDoc/MMT theories (ca. 260,000).
%The main problem solved here was to parse the formula section (generating functions, relations between sequences, \ldots): they are represented in a human-oriented ASCII syntax, which is highly irregular, ill-separated from surrounding text, and interpunctuation.
%Nonetheless we managed to recover ca. 90\% of the formulae and
%\begin{compactenum}[\em i\rm)]
%\item generate ca. 100,000 new relations between sequences and
%\item provide a package of ca. 50,000 generating functions to Sage (which can be used
%  e.g. in the FindStat database).
%\end{compactenum}
%We use this theory set to test the functionalities of ``virtual theory graphs'' (one step up from the ``virtual theories'' developed in \localtaskref{dksbases}{data-design}).
\medskip

\subparagraph{\longtaskref{dksbases}{data-findstat}}
\label{dksbases@data-findstat}
This task was addressed in the second reporting period.
%We have seen that the \LMFDB already shows all the complexities needed to develop full-coverage DKS functionality for the \pn VRE toolkit.
%On the other hand our survey shows that our DKS design (OMDoc/MMT virtual theories) is sufficient for covering the FindStat use case as well.
%Therefore we have delayed this taks to the last year of the \pn project, when the system API theories for \Sage and OEIS have matured. With the declarative design of the virtual theories, task \localtaskref{dksbases}{data-findstat} becomes a matter of writing down the schema theories system API theories for FindStat and defining the requisite codecs. We expect this to be a matter of one of two weeks of joint development of the FAU team together with UPSud. 
\medskip

\subparagraph{\longtaskref{dksbases}{data-LMFDB}}
\label{dksbases@data-LMFDB}
Work on this task had already started in the second report period. There we had used the concept of virtual theories developed in \localtaskref{dksbases}{data-triform} to MitM-integrate (parts of) the LMFDB and make it interoperable as a VRE component.
During this process, it became apparent that to achieve meaningful interoperability (the I in FAIR), we have to model the mathematical datasets as described above.
This prompted us to refocus on an integration into the \pn VRE toolkit at the dataset level, not at the level of systems like OEIS, FindStat, or LMFDB.
Indeed, LMFDB is itself a collection of over 80 datasets and the work on the semantics and representation of datasets catalyzed a large inventory of datasets in LMFDB.
At the start of the \pn project, LMFDB had been growing organically based on the schema-less MongoDB database, and no-one had an complete overview on the details and extent of the content.
The Warwick group led a move to inventory all the data sets, and to (manually) recover their specifications at the mathematical and data base level (schema information), which has in turn facilitated the recent move from MongoDB to PostGreSQL (independent of \pn).
Another fruit of the \pn work was an vastly improved and more semantic API for LMFDB (see \url{http://www.lmfdb.org/api2/}) that has recently come online.
LMFDB’s earlier API was just a very thin HTTP wrapper over the database core of LMFDB.
API2 adds full SQL querying support and first steps towards ``semantic/mathematic'' queries.
A \Sage interface based on API2 is currently under development.

While the LMFDB has ``retrofitted'' a more semantic treatment of datasets on LMFDB, the FAU group has explored building a dataset hosting system and user interface based on the MitM model from scratch.
The \dmh system leverages the MitM ontology for specifying the mathematical objects in a dataset and extends MitM with a set of MDDL (Math Dataset Description Language) specifications that link the mathematical specifications with database schemata.
The MDDL specifications are implemented in a set of codecs that implement the transformations between the layers, encapsulate the translations of mathematical queries to SQL queries in the underlying database generated from MDDL, and provide user interface widgets for the corresponding mathematical types.
We have tested this setup on five external data sets -- we did not want to duplicate work with LMFDB -- and so far the \dmh design seems to scale.
When the set of codecs collected in \dmh and made available for reuse by other datasets reaches a point of saturation, we expect joining the costs for \dmh to become restricted to the dataset-immanent information.
\medskip

\subparagraph{\longtaskref{dksbases}{data-memo}}
\label{dksbases@data-memo}
We have developed persistent memoization modules for Sage and Gap that can use both local and remote data stores.
Both use the same format so they can share the same data stores.\ednote{to be finished by sites US,PS,UW}

We report on this task in detail in \delivref{dksbases}{persistent-memoization}.
\medskip

\subparagraph{\longtaskref{dksbases}{mws}}
This task runs over the whole length of the \pn project. The third reporting period with its refined model of the semantic level of mathematical VRE components has given us a new view on the \taskref{dksbases}{mws} as well.

Generally, search is one of the FAIR principles of research data (F), and adapting it to mathematical data/knowledge/software has been one of the central topics in \WPref{dksbases} (and \WPref{UI}). In the grant proposal we had concentrated on formula- and full-text search, but our deeper understanding of the categories of mathematical data (see ~\cite{ODK-D6.10}) developed during the \pn project showed that for mathematical semantic search we need to take the kind of data into account better.
\begin{compactitem}
\item For \textbf{symbolic data} (organization and inference in Figure~\ref{fig:tetrapod}), formula search as reported on in \cite{ODK-D6.1} is sufficient as long as the context of all formulas is included in the search index. For this, we have pioneered an export of the knowledge base of the Isabelle system (and others) into symbolic OMDoc formulae and RDF triples that they can be searched via SPARQL queries. See our description of the new \taskref{dksbases}{isabelle} below for details.
\item In \textbf{narrative data}, we need full-text search capabilities; this has been addressed in the first reporting period -- see \cite{ODK-D6.1} again.
\item For \textbf{tabulated data}, we need a mathematical query language in which users can express information needs at the mathematical level, and which can be compiled into e.g. SQL queries at the database level.
  This was initiated in the second reporting period.
   In the third reporting period, it has greatly matured, been integrated into the new \dmh system, and extended by a user interface generation system.
\item For \textbf{computational data}, i.e. mathematical software, there are two options: we can search source code, or we can search the mathematical artefacts in the programs.
  As source code search is already provided by repository hosting systems like GitHub or GitLab we have concentrated on the latter.
  Concretely, we built a system to harvest mathematical formulae from Jupyter notebooks, index them in the MathWebSearch engine, and provide a specialized user interface for searching them.
  The main technical development has been to make the MathWebSearch engine -- which had been mostly experimental -- more deployable and manageable so that it can be used as a VRE component and so that it can be integrated into the \pn VRE toolkit without developing instance-specific code. 
\end{compactitem}
We have reported on all the aspects of this task in detail in \cite{ODK-D6.10}.
\medskip

\subparagraph{\longtaskref{dksbases}{isabelle}}
For many decades, the development of a universal database of all mathematical knowledge, as envisioned, e.g., in the QED manifesto \cite{qed}, has been a major driving force of computer mathematics.
Today a variety of such libraries are available.
These are most prominently developed in proof assistants such as Coq \cite{coq} or Isabelle \cite{isabelle} and are treasure troves of detailed mathematical knowledge.
Within \pn, we have developed interface standards, specifically OMDoc for symbolic and ULO for relational knowledge, that allow maintainers of formal libraries to make their content available to outside systems.

In this task (which has been added in the last amendment of the grant agreement), we have exported the large Isabelle knowledge base as both OMDoc/MMT and ULO format
Concretely, we have built an exporter from the Isabelle Theorem prover library (Archive of Formal Proof) to both MMT and RDF data.
This exporter is now part of the latest releases of both Isabelle and MMT, and the exported data is available online.

We report on this task in detail in \delivref{dksbases}{nbad-search}.


%%% Local Variables:
%%% mode: latex 
%%% mode: visual-line
%%% fill-column: 5000
%%% TeX-master: "report"
%%% End:

%  LocalWords:  subsubsection dksbases ystok WPref compactitem emph DehKohKon:iop16 textbf taskref longdelivref lfmverif triformal formalized biformal HorRoz:ossp09 medskip longmilestoneref dksbases-interop1 dksbases-interop2 characterized WieKohRab:vtuimkb17 psfoundation delivref KohMuePfe:kbimss17 regularized synchronized ldots interpunctuation compactenum mws KohMuePfe:kbimss17,WieKohRab:vtuimkb17 CreLow:mdcmds18 jupyter-import Jupyter MitM-based Jupyter Cernay Cernay tetrapodal organization CarFarKohRab:bmobb19 losslessly dmh BerKohRab:tumdi19,ODK-D6.10 MitM-integrate oldpart dksbases@data-findstat ednote nbad-search newpart specialized catalyzed
